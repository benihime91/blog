{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Neural-Network from scratch\n",
    "> A tutorial to code a neural network from scratch in python using numpy.\n",
    "\n",
    "- toc: false\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [machinelearning, deeplearning, python3.x, numpy]\n",
    "- image: images/backprop.jpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will assume that you all know what a artificial neural network is and have a little bit of knowledge about `forward and backward propagation`. Just having a simple idea is enough.\n",
    "\n",
    "> Tip: If you do not know what the above terms are or would like to brush up on the topics, I would suggest going through this amazing [youtube playlist](https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) by [3Blue1Brown](https://www.3blue1brown.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> youtube: https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_input\n",
    "import warnings\n",
    "np.random.seed(123)\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this blog post, we'll use one of the most famous datasets in computer vision, [MNIST](https://en.wikipedia.org/wiki/MNIST_database). MNIST contains images of handwritten digits, collected by the National Institute of Standards and Technology and collated into a machine learning dataset by Yann Lecun and his colleagues. Lecun used MNIST in 1998 in [Lenet-5](http://yann.lecun.com/exdb/lenet/), the first computer system to demonstrate practically useful recognition of handwritten digit sequences. This was one of the most important breakthroughs in the history of AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code given below to download the `MNIST` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell\n",
    "wget -P path http://deeplearning.net/data/mnist/mnist.pkl.gz\n",
    "```\n",
    "\n",
    "> Note: the above code snippet will download the dataset to `{path}` so be sure to set the `{path}` to the desired location of your choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (50000, 784)\n",
      "Total number of examples: 50000\n",
      "Number of pixel values per image: 784\n"
     ]
    }
   ],
   "source": [
    "def get_data(path):\n",
    "    \"\"\"\n",
    "    Fn to unzip the MNIST data and return\n",
    "    the data as numpy arrays\n",
    "    \"\"\"\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "    return map(np.array, (x_train,y_train,x_valid,y_valid))\n",
    "\n",
    "\n",
    "# Grab the MNIST dataset\n",
    "x_train,y_train,x_valid,y_valid = get_data(path= \"../../Datasets/mnist.pkl.gz\")\n",
    "\n",
    "tots,feats = x_train.shape\n",
    "print(\"Shape of x_train:\",x_train.shape)\n",
    "print(\"Total number of examples:\", tots)\n",
    "print(\"Number of pixel values per image:\", feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing our `train` & `validation` datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our life a bit easier we are going to take only the examples that contain a 1 or 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10610, 784), (10610, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_mask = [y_train==0] # grab all the index values where 0 is present\n",
    "one_mask = [y_train==1] # grad all the index valus where 1 is present\n",
    "\n",
    "# grab all the 1's and 0's and make training set\n",
    "x_train = np.vstack((x_train[zero_mask], x_train[one_mask]))\n",
    "y_train = np.reshape(y_train, (-1,1))\n",
    "y_train = np.squeeze(np.vstack((y_train[zero_mask], y_train[one_mask]))).reshape(-1,1)\n",
    "\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our training set now has 10610 examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2055, 784), (2055, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_mask = [y_valid==0] # grab all the index values where 0 is present\n",
    "one_mask = [y_valid==1] # grad all the index valus where 1 is present\n",
    "\n",
    "# grab all the 1's and 0's and make training set\n",
    "x_valid = np.vstack((x_valid[zero_mask], x_valid[one_mask]))\n",
    "y_valid = np.reshape(y_valid, (-1,1))\n",
    "y_valid = np.squeeze(np.vstack((y_valid[zero_mask], y_valid[one_mask]))).reshape(-1,1)\n",
    "\n",
    "x_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our validation set now has 2055 examples**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why do we need different training and validation sets ?**\n",
    "\n",
    "Since, this topic requires a different post on it's own I won't be covering it here. But you can get the idea from this above video:\n",
    "\n",
    "> youtube: https://youtu.be/1waHlpKiNyY?t=243"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view some example images from our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#collapse \n",
    "plt.imshow(x_train[50].reshape(28,28), cmap=\"gray\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#collapse\n",
    "plt.imshow(x_train[5000].reshape(28,28), cmap=\"gray\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task we are going to use a very basic model architecture this 2 linear layers and a output layer with 1 unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_input \n",
    "import graphviz\n",
    "def gv(s): return graphviz.Source('digraph G{ rankdir=\"LR\"' + s + '; }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's take a deep dive into what this network means:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take at look at all the individual components of this network:\n",
    "- **Linear:**\n",
    "  The linear layer computes the following :      \n",
    "   ```\n",
    "   out = matmul(input,W1) + B1\n",
    "   ```\n",
    "   \n",
    "- **ReLU:** \n",
    "  The relu computes the following:\n",
    "  ```\n",
    "  out = max(0, input)\n",
    "  ```\n",
    "- **Sigmoid:** \n",
    "  The sigmoid computes the following:\n",
    "  ```\n",
    "  out = 1/(1 + e.pow(input))\n",
    "  ```\n",
    "  \n",
    "- **Loss:** \n",
    "  For the loss we are going to use the CrossEntropy Loss which is defined by the follwoing equation:\n",
    "  $$loss= -\\frac{1}{m} \\sum\\limits_{i = 1}^{m} (y^{(i)}\\log\\left(yhat^{(i)}\\right) + (1-y^{(i)})\\log\\left(1-yhat^{(i)}\\right)) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that we have our model architecture, let's create the different parts needed to assemble the model:**\n",
    "- linear layer\n",
    "- relu activation\n",
    "- sigmoid activation\n",
    "- loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's first try to make some sense of what is happening in the backward and forward pass of our model:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On paper our forward pass would look something like this:**\n",
    "\n",
    "> Note: `@` in python is the `matrix-multiplication operator`. \n",
    "\n",
    "```python\n",
    "inputs = x_train # original inputs\n",
    "targets = y_train # original targets\n",
    "\n",
    "# forward pass for the 1st linear layer\n",
    "z1 = inputs @ w2 + b2\n",
    "a1 = relu(z1)\n",
    "# forward pass for the 2nd linear layer\n",
    "z2 = a1 @ w2 + b2\n",
    "a2 = relu(z2)\n",
    "# forward pass for the output linear layer\n",
    "z3 = a2 @ w3 + b3\n",
    "pred = a3 = sigmoid(z3) # these are our model predictions \n",
    "# calculate loss between original targets & model predictions\n",
    "loss = loss_fn(a3, targets)\n",
    "```\n",
    "> Note: This is not actual code it's just psuedo-code for understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Forward pass :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.44.0 (20200408.0750)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"811pt\" height=\"260pt\"\n",
       " viewBox=\"0.00 0.00 810.56 260.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-256 806.56,-256 806.56,4 -4,4\"/>\n",
       "<!-- X -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "<!-- linear1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>linear1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"125.1\" cy=\"-180\" rx=\"35.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"125.1\" y=\"-176.3\" font-family=\"Times,serif\" font-size=\"14.00\">linear1</text>\n",
       "</g>\n",
       "<!-- X&#45;&gt;linear1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>X&#45;&gt;linear1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M48.38,-222.55C60.94,-215.49 77.34,-206.28 91.66,-198.23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"93.7,-201.1 100.7,-193.15 90.27,-194.99 93.7,-201.1\"/>\n",
       "</g>\n",
       "<!-- relu1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>relu1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"224.79\" cy=\"-180\" rx=\"28.7\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"224.79\" y=\"-176.3\" font-family=\"Times,serif\" font-size=\"14.00\">relu1</text>\n",
       "</g>\n",
       "<!-- linear1&#45;&gt;relu1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>linear1&#45;&gt;relu1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M160.27,-180C168.56,-180 177.47,-180 185.93,-180\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"185.93,-183.5 195.93,-180 185.93,-176.5 185.93,-183.5\"/>\n",
       "</g>\n",
       "<!-- linear2 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>linear2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"324.49\" cy=\"-126\" rx=\"35.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"324.49\" y=\"-122.3\" font-family=\"Times,serif\" font-size=\"14.00\">linear2</text>\n",
       "</g>\n",
       "<!-- relu1&#45;&gt;linear2 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>relu1&#45;&gt;linear2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M246.99,-168.28C259.79,-161.21 276.36,-152.05 290.81,-144.06\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"292.87,-146.92 299.93,-139.02 289.49,-140.79 292.87,-146.92\"/>\n",
       "</g>\n",
       "<!-- relu2 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>relu2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"424.18\" cy=\"-126\" rx=\"28.7\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"424.18\" y=\"-122.3\" font-family=\"Times,serif\" font-size=\"14.00\">relu2</text>\n",
       "</g>\n",
       "<!-- linear2&#45;&gt;relu2 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>linear2&#45;&gt;relu2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M359.65,-126C367.95,-126 376.86,-126 385.32,-126\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"385.32,-129.5 395.32,-126 385.32,-122.5 385.32,-129.5\"/>\n",
       "</g>\n",
       "<!-- linear3 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>linear3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"523.87\" cy=\"-72\" rx=\"35.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"523.87\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\">linear3</text>\n",
       "</g>\n",
       "<!-- relu2&#45;&gt;linear3 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>relu2&#45;&gt;linear3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M446.38,-114.28C459.18,-107.21 475.75,-98.05 490.2,-90.06\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"492.26,-92.92 499.32,-85.02 488.88,-86.79 492.26,-92.92\"/>\n",
       "</g>\n",
       "<!-- sigmoid -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>sigmoid</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"634.62\" cy=\"-72\" rx=\"39.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"634.62\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\">sigmoid</text>\n",
       "</g>\n",
       "<!-- linear3&#45;&gt;sigmoid -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>linear3&#45;&gt;sigmoid</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M558.98,-72C567.13,-72 575.99,-72 584.66,-72\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"584.7,-75.5 594.7,-72 584.7,-68.5 584.7,-75.5\"/>\n",
       "</g>\n",
       "<!-- prediction -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>prediction</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"756.41\" cy=\"-72\" rx=\"46.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"756.41\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\">prediction</text>\n",
       "</g>\n",
       "<!-- sigmoid&#45;&gt;prediction -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>sigmoid&#45;&gt;prediction</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M674.51,-72C682.66,-72 691.41,-72 700.03,-72\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"700.05,-75.5 710.05,-72 700.05,-68.5 700.05,-75.5\"/>\n",
       "</g>\n",
       "<!-- W1 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>W1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-180\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-176.3\" font-family=\"Times,serif\" font-size=\"14.00\">W1</text>\n",
       "</g>\n",
       "<!-- W1&#45;&gt;linear1 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>W1&#45;&gt;linear1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54.01,-180C61.92,-180 70.84,-180 79.61,-180\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"79.76,-183.5 89.76,-180 79.76,-176.5 79.76,-183.5\"/>\n",
       "</g>\n",
       "<!-- B1 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>B1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-126\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-122.3\" font-family=\"Times,serif\" font-size=\"14.00\">B1</text>\n",
       "</g>\n",
       "<!-- B1&#45;&gt;linear1 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>B1&#45;&gt;linear1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M48.38,-137.45C60.94,-144.51 77.34,-153.72 91.66,-161.77\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"90.27,-165.01 100.7,-166.85 93.7,-158.9 90.27,-165.01\"/>\n",
       "</g>\n",
       "<!-- W2 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>W2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"224.79\" cy=\"-126\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"224.79\" y=\"-122.3\" font-family=\"Times,serif\" font-size=\"14.00\">W2</text>\n",
       "</g>\n",
       "<!-- W2&#45;&gt;linear2 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>W2&#45;&gt;linear2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M251.97,-126C260.27,-126 269.68,-126 278.89,-126\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"279.14,-129.5 289.14,-126 279.14,-122.5 279.14,-129.5\"/>\n",
       "</g>\n",
       "<!-- B2 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>B2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"224.79\" cy=\"-72\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"224.79\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\">B2</text>\n",
       "</g>\n",
       "<!-- B2&#45;&gt;linear2 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>B2&#45;&gt;linear2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M246.03,-83.19C258.99,-90.35 276.1,-99.81 290.94,-108.01\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"289.38,-111.15 299.83,-112.92 292.77,-105.02 289.38,-111.15\"/>\n",
       "</g>\n",
       "<!-- W3 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>W3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"424.18\" cy=\"-72\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"424.18\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\">W3</text>\n",
       "</g>\n",
       "<!-- W3&#45;&gt;linear3 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>W3&#45;&gt;linear3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M451.36,-72C459.66,-72 469.07,-72 478.28,-72\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"478.53,-75.5 488.53,-72 478.53,-68.5 478.53,-75.5\"/>\n",
       "</g>\n",
       "<!-- B3 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>B3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"424.18\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"424.18\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">B3</text>\n",
       "</g>\n",
       "<!-- B3&#45;&gt;linear3 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>B3&#45;&gt;linear3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M445.42,-29.19C458.38,-36.35 475.49,-45.81 490.33,-54.01\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"488.77,-57.15 499.22,-58.92 492.16,-51.02 488.77,-57.15\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7febe9066710>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "gv('''\n",
    "X->linear1->relu1->linear2->relu2->linear3->sigmoid->prediction\n",
    "\n",
    "W1->linear1\n",
    "B1->linear1\n",
    "\n",
    "W2->linear2\n",
    "B2->linear2\n",
    "\n",
    "W3->linear3\n",
    "B3->linear3\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.44.0 (20200408.0750)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"299pt\" height=\"98pt\"\n",
       " viewBox=\"0.00 0.00 299.09 98.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 94)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-94 295.09,-94 295.09,4 -4,4\"/>\n",
       "<!-- prediction -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>prediction</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"46.15\" cy=\"-72\" rx=\"46.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"46.15\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\">prediction</text>\n",
       "</g>\n",
       "<!-- loss_fn -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>loss_fn</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"164.69\" cy=\"-45\" rx=\"36.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"164.69\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\">loss_fn</text>\n",
       "</g>\n",
       "<!-- prediction&#45;&gt;loss_fn -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>prediction&#45;&gt;loss_fn</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M86.28,-62.93C97.63,-60.3 110.08,-57.42 121.6,-54.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"122.49,-58.14 131.45,-52.47 120.91,-51.32 122.49,-58.14\"/>\n",
       "</g>\n",
       "<!-- loss -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>loss</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"264.09\" cy=\"-45\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"264.09\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\">loss</text>\n",
       "</g>\n",
       "<!-- loss_fn&#45;&gt;loss -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>loss_fn&#45;&gt;loss</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M201.13,-45C209.46,-45 218.36,-45 226.74,-45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"226.99,-48.5 236.99,-45 226.99,-41.5 226.99,-48.5\"/>\n",
       "</g>\n",
       "<!-- target -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>target</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"46.15\" cy=\"-18\" rx=\"30.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"46.15\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">target</text>\n",
       "</g>\n",
       "<!-- target&#45;&gt;loss_fn -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>target&#45;&gt;loss_fn</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M74.76,-24.4C88.68,-27.62 105.85,-31.6 121.39,-35.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"120.78,-38.65 131.31,-37.5 122.36,-31.83 120.78,-38.65\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7febe920de10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "gv('''\n",
    "prediction->loss_fn\n",
    "target->loss_fn\n",
    "loss_fn-> loss\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consequently our backward pass would look something like this :** \n",
    "\n",
    "(Let us assume that the `grad(inp, out)` computes the gradients of `inp` wrt `out`)\n",
    "\n",
    "```python\n",
    "# gradient of loss wrt to the output of the last activation layer: (a3)\n",
    "# (or the predictions of model)\n",
    "da3 = grad(loss, a3)\n",
    "\n",
    "# gradient of loss wrt to the output of the current linear layer: (z3)\n",
    "dz3 = grad(loss, z3) = grad(loss, a3) * grad(a3, z3)\n",
    "# gradient of loss wrt to w3\n",
    "dw3 = grad(loss, w3) = grad(loss, z3) * grad(z3, w3) = dz3 * grad(z3, w3)\n",
    "# gradient of loss wrt to b3\n",
    "db3 = grad(loss, b3) = grad(loss, z3) * grad(z3, b3) = dz3 * grad(z3, b3)\n",
    "# gradient of loss wrt to the input of the current linear layer: (a2)\n",
    "da2 = grad(loss, a2) = grad(loss, a3) = grad(a2, )\n",
    "\n",
    "# gradient of loss wrt to the output of the current linear layer: (z2)\n",
    "dz2 = grad(loss, z2) = grad(loss, a2) * grad(a2, z2) \n",
    "# gradient of loss wrt to w2\n",
    "dw2 = grad(loss, w2) = grad(loss, z2) * grad(z2, w2) = dz2 * grad(z2, w2)\n",
    "# gradient of loss wrt to b2\n",
    "db2 = grad(loss, b2) = grad(loss, z2) * grad(z2, b2) = dz2 * grad(z2, b2)\n",
    "# gradient of loss wrt to the input of the current linear layer: (a1)\n",
    "da1 = grad(loss, a1) = grad(loss, z2) * grad(z2, a1) = dz2 * grad(z2, a1)\n",
    "\n",
    "# gradient of loss wrt to the output of the current linear layer: (z1)\n",
    "dz1 = grad(loss, z1) = grad(loss, a1) * grad(a1, z1) = da1 * grad(a1, z1)\n",
    "# gradient of loss wrt to w1\n",
    "dw1 = grad(loss, w1) = grad(loss, z1) * grad(z1, w1) = dz1 * grad(z1, w1)\n",
    "# gradient of loss wrt to b1\n",
    "db1 = grad(loss, b1) = grad(loss, z1) * grad(z1, 1) = dz1 * grad(z1, b1)\n",
    "# In this layer the inputs are out training examples which we cannot change so\n",
    "# we do not need to commpute more gradients\n",
    "\n",
    "# Update parameters :\n",
    "# since we now have all the required gradients we can now perform the update step\n",
    "w1 -= learning_rate * dw1\n",
    "b1 -= learning_rate * db1\n",
    "\n",
    "w2 -= learning_rate * dw2\n",
    "b2 -= learning_rate * db2\n",
    "```\n",
    "> Note: This is not actual code it's just psuedo-code for understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Backward pass:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.44.0 (20200408.0750)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"773pt\" height=\"233pt\"\n",
       " viewBox=\"0.00 0.00 772.86 233.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 229)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-229 768.86,-229 768.86,4 -4,4\"/>\n",
       "<!-- Loss -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>Loss</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27.3\" cy=\"-153\" rx=\"27.1\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27.3\" y=\"-149.3\" font-family=\"Times,serif\" font-size=\"14.00\">Loss</text>\n",
       "</g>\n",
       "<!-- sigmoid -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>sigmoid</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"130.24\" cy=\"-153\" rx=\"39.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"130.24\" y=\"-149.3\" font-family=\"Times,serif\" font-size=\"14.00\">sigmoid</text>\n",
       "</g>\n",
       "<!-- Loss&#45;&gt;sigmoid -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>Loss&#45;&gt;sigmoid</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54.82,-153C62.63,-153 71.43,-153 80.18,-153\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"80.36,-156.5 90.36,-153 80.36,-149.5 80.36,-156.5\"/>\n",
       "</g>\n",
       "<!-- linear3 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>linear3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"240.99\" cy=\"-153\" rx=\"35.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"240.99\" y=\"-149.3\" font-family=\"Times,serif\" font-size=\"14.00\">linear3</text>\n",
       "</g>\n",
       "<!-- sigmoid&#45;&gt;linear3 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>sigmoid&#45;&gt;linear3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M170.19,-153C178.43,-153 187.17,-153 195.59,-153\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"195.63,-156.5 205.63,-153 195.63,-149.5 195.63,-156.5\"/>\n",
       "</g>\n",
       "<!-- W3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>W3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"340.68\" cy=\"-207\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"340.68\" y=\"-203.3\" font-family=\"Times,serif\" font-size=\"14.00\">W3</text>\n",
       "</g>\n",
       "<!-- linear3&#45;&gt;W3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>linear3&#45;&gt;W3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M265.63,-166.07C279.07,-173.5 296,-182.86 310.29,-190.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"308.78,-193.92 319.23,-195.69 312.17,-187.79 308.78,-193.92\"/>\n",
       "</g>\n",
       "<!-- B3 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>B3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"340.68\" cy=\"-153\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"340.68\" y=\"-149.3\" font-family=\"Times,serif\" font-size=\"14.00\">B3</text>\n",
       "</g>\n",
       "<!-- linear3&#45;&gt;B3 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>linear3&#45;&gt;B3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M276.15,-153C284.93,-153 294.41,-153 303.3,-153\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"303.38,-156.5 313.38,-153 303.38,-149.5 303.38,-156.5\"/>\n",
       "</g>\n",
       "<!-- relu2 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>relu2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"340.68\" cy=\"-99\" rx=\"28.7\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"340.68\" y=\"-95.3\" font-family=\"Times,serif\" font-size=\"14.00\">relu2</text>\n",
       "</g>\n",
       "<!-- linear3&#45;&gt;relu2 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>linear3&#45;&gt;relu2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M265.63,-139.93C278.88,-132.61 295.54,-123.4 309.69,-115.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"311.52,-118.57 318.58,-110.67 308.13,-112.44 311.52,-118.57\"/>\n",
       "</g>\n",
       "<!-- linear2 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>linear2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"440.37\" cy=\"-99\" rx=\"35.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"440.37\" y=\"-95.3\" font-family=\"Times,serif\" font-size=\"14.00\">linear2</text>\n",
       "</g>\n",
       "<!-- relu2&#45;&gt;linear2 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>relu2&#45;&gt;linear2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M369.41,-99C377.36,-99 386.23,-99 394.91,-99\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"394.96,-102.5 404.96,-99 394.96,-95.5 394.96,-102.5\"/>\n",
       "</g>\n",
       "<!-- W2 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>W2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"540.07\" cy=\"-153\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"540.07\" y=\"-149.3\" font-family=\"Times,serif\" font-size=\"14.00\">W2</text>\n",
       "</g>\n",
       "<!-- linear2&#45;&gt;W2 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>linear2&#45;&gt;W2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M465.02,-112.07C478.46,-119.5 495.39,-128.86 509.67,-136.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"508.17,-139.92 518.61,-141.69 511.56,-133.79 508.17,-139.92\"/>\n",
       "</g>\n",
       "<!-- B2 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>B2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"540.07\" cy=\"-99\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"540.07\" y=\"-95.3\" font-family=\"Times,serif\" font-size=\"14.00\">B2</text>\n",
       "</g>\n",
       "<!-- linear2&#45;&gt;B2 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>linear2&#45;&gt;B2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M475.54,-99C484.32,-99 493.8,-99 502.69,-99\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"502.77,-102.5 512.77,-99 502.77,-95.5 502.77,-102.5\"/>\n",
       "</g>\n",
       "<!-- relu1 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>relu1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"540.07\" cy=\"-45\" rx=\"28.7\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"540.07\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\">relu1</text>\n",
       "</g>\n",
       "<!-- linear2&#45;&gt;relu1 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>linear2&#45;&gt;relu1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M465.02,-85.93C478.27,-78.61 494.93,-69.4 509.08,-61.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"510.9,-64.57 517.96,-56.67 507.52,-58.44 510.9,-64.57\"/>\n",
       "</g>\n",
       "<!-- linear1 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>linear1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"639.76\" cy=\"-45\" rx=\"35.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"639.76\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\">linear1</text>\n",
       "</g>\n",
       "<!-- relu1&#45;&gt;linear1 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>relu1&#45;&gt;linear1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M568.8,-45C576.75,-45 585.62,-45 594.3,-45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"594.34,-48.5 604.34,-45 594.34,-41.5 594.34,-48.5\"/>\n",
       "</g>\n",
       "<!-- W1 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>W1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"737.86\" cy=\"-72\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"737.86\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\">W1</text>\n",
       "</g>\n",
       "<!-- linear1&#45;&gt;W1 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>linear1&#45;&gt;W1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M670.9,-53.47C681.08,-56.33 692.51,-59.54 702.96,-62.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"702.03,-65.85 712.6,-65.19 703.92,-59.11 702.03,-65.85\"/>\n",
       "</g>\n",
       "<!-- B1 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>B1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"737.86\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"737.86\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">B1</text>\n",
       "</g>\n",
       "<!-- linear1&#45;&gt;B1 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>linear1&#45;&gt;B1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M670.9,-36.53C681.08,-33.67 692.51,-30.46 702.96,-27.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"703.92,-30.89 712.6,-24.81 702.03,-24.15 703.92,-30.89\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7febe92148d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "gv('''\n",
    "Loss -> sigmoid->linear3\n",
    "linear3->W3\n",
    "linear3->B3\n",
    "linear3->relu2->linear2\n",
    "\n",
    "linear2->W2\n",
    "linear2->B2\n",
    "linear2->relu1->linear1\n",
    "\n",
    "linear1->W1\n",
    "linear1->B1\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `Linear` Layer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code creates a `Linear class` which represents a `Linear` layer in our neural-network. The `forward function` of the class implements the of the `layer's forward propagation` & the `backward function` implements the `layers's backward propagation`. Let's go to detail into what the code means:\n",
    "\n",
    "- **Forward:**  \n",
    "This part is quite straight-forward it computes the dot-product between the **`input`** and the **`weights`** & adds the **`bias`** term to get **`z`**. It also stores all the intermidiate values generated to use in the backward pass.\n",
    "\n",
    "\n",
    "- **Backward:**\n",
    "    * The backward method of the class **`Linear`** takes in the argument **`grads`**. \n",
    "    * **`grads`** is the gradient of the loss wrt to the output of the current linear layer ie., **`dz`** if we were to follow the nomenclature of our pseudo-code.\n",
    "    * To succesfully compute the backward pass for our linear layer we need the following:\n",
    "        - **`grad(z, w)`** \n",
    "        - **`grad(z, b)`**\n",
    "        - **`grad(z, a_prev)`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> Note: `z`, `w`, `b`, `a_prev` are the outputs, weights, bias and input-activations of the Linear layer respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, w, b):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        \"\"\"\n",
    "        Implement the linear part of a layer's forward propagation.\n",
    "        \n",
    "        Args:\n",
    "            inp : activations from previous layer (or input data)\n",
    "        \n",
    "        Returns:\n",
    "\n",
    "            z  : the input of the activation function, also called pre-activation parameter \n",
    "        \"\"\"\n",
    "        self.inp = inp\n",
    "        self.z   = inp @ self.w + self.b\n",
    "        return self.z\n",
    "    \n",
    "    def backward(self, grads):\n",
    "        \"\"\"\n",
    "        Implement the linear portion of backward propagation for a single layer.\n",
    "\n",
    "        Args:\n",
    "            grads :  Gradient of the cost with respect to the linear output. \n",
    "                     or the accumulated gradients from the prev layers. \n",
    "                     This is used for the chain rule to compute the gradients.\n",
    "        Returns:\n",
    "            da : Gradient of cost wrt to the activation of the previous layer or the input of the \n",
    "                 current layer.\n",
    "            dw : Gradient of the cost with respect to W\n",
    "            db : Gradient of the cost with respect to b\n",
    "        \"\"\"\n",
    "        m = self.inp.shape[1]\n",
    "        # gradient of loss wrt to the weights\n",
    "        dw = 1/m * (self.inp.T @ grads)\n",
    "        # gradient of the loss wrt to the bias\n",
    "        db = 1/m * np.sum(grads, axis=0, keepdims=True)\n",
    "        # gradient of the loss wrt to the input of the linear layer\n",
    "        # this is used to continue the chain rule\n",
    "        da_prev = grads @ self.w.T \n",
    "        return (da_prev, dw, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `ReLU` Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Forward**:  \n",
    "The mathematical formula for ReLU is $A = RELU(Z) = max(0, Z)$\n",
    "- **Backward**:  \n",
    "During the backward pass the relu accepts the gradients of the `loss wrt to the activation` i.e, `da` then computes\n",
    "the gradients of the `loss wrt to the input-of-relu(z)` i.e, `dz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelU:\n",
    "    def forward(self, inp):\n",
    "        \"\"\"\n",
    "        Implement the RELU function.\n",
    "\n",
    "        Args:\n",
    "            inp : Output of the linear layer, of any shape\n",
    "\n",
    "        Returns:\n",
    "            a  : Post-activation parameter, of the same shape as Z\n",
    "        \"\"\"\n",
    "        self.inp = inp\n",
    "        self.output = np.maximum(0, self.inp)\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, grads):\n",
    "        \"\"\"\n",
    "        Implement the backward propagation for a single RELU unit.\n",
    "\n",
    "        Ars:\n",
    "            grads : gradients of the loss wrt to the activation output\n",
    "\n",
    "        Returns:\n",
    "            dz : Gradient of the loss with respect to the input of the activation\n",
    "        \"\"\"\n",
    "        dz = np.array(grads, copy=True)\n",
    "        dz[self.inp <= 0] = 0\n",
    "        return dz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `sigmoid` Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sigmoid layer functions in exactly the same way as the `ReLU` layer . The only difference is the forward pass output calculation. \n",
    "\n",
    "\n",
    "In the `sigmoid layer`:  $\\sigma(Z) = \\frac{1}{ 1 + e^{-(W A + b)}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def forward(self, inp):\n",
    "        \"\"\"\n",
    "        Implements the sigmoid activation in numpy\n",
    "\n",
    "        Args:\n",
    "            inp: numpy array of any shape\n",
    "\n",
    "        Returns:\n",
    "            a  : output of sigmoid(z), same shape as inp\n",
    "        \"\"\"\n",
    "        self.inp = inp\n",
    "        self.out =  1/(1+np.exp(-self.inp))\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self, grads):\n",
    "        \"\"\"\n",
    "        Implement the backward propagation for a single sigmoid unit.\n",
    "\n",
    "        Args:\n",
    "            grads : gradients of the loss wrt to the activation output\n",
    "\n",
    "        Returns:\n",
    "            dz : Gradient of the loss with respect to the input of the activation\n",
    "        \"\"\"\n",
    "        s = 1/(1+np.exp(-self.inp))\n",
    "        dz = grads * s * (1-s)\n",
    "        return dz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Loss` function :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task we are going to use the [CrossEntropy Loss](https://en.wikipedia.org/wiki/Cross_entropy)\n",
    "\n",
    "The `forward` pass of the CrossEntropy Loss is computed as follows: \n",
    "$$loss= -\\frac{1}{m} \\sum\\limits_{i = 1}^{m} (y^{(i)}\\log\\left(yhat^{(i)}\\right) + (1-y^{(i)})\\log\\left(1-yhat^{(i)}\\right)) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CELoss():\n",
    "    def forward(self, pred, target):\n",
    "        \"\"\"\n",
    "        Implement the CrossEntropy loss function.\n",
    "\n",
    "        Args:\n",
    "            pred   : predicted labels from the neural network\n",
    "            target : true \"label\" labels\n",
    "        Returns:\n",
    "            loss   : cross-entropy loss\n",
    "        \"\"\"\n",
    "        self.yhat = pred\n",
    "        self.y = target\n",
    "        m = self.y.shape[0]\n",
    "        # commpute loss\n",
    "        term1 = (np.multiply(self.y, np.log(self.yhat)))\n",
    "        term2 = (np.multiply((1-self.y),(np.log(1-self.yhat))))\n",
    "        loss = -1/m * np.sum(term1+term2)\n",
    "        self.output = loss\n",
    "        return np.squeeze(self.output) # convert array to a single value number\n",
    "    \n",
    "    def backward(self):\n",
    "        \"\"\"\n",
    "        Computes the gradinets of the loss_fn wrt to the predicted labels\n",
    "        \n",
    "        Returns:\n",
    "         da : derivative of loss_fn wrt to the predicted labels\n",
    "        \"\"\"\n",
    "        # derivative of loss_fn with respect to a [predicted labels]\n",
    "        da = - (np.divide(self.y, self.yhat) - np.divide(1 - self.y, 1 - self.yhat)) \n",
    "        return da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model:\n",
    "\n",
    "**Let's go over the architecture that we are going to use for our neural netwok:**\n",
    "\n",
    "- Our model is going to have 2 hidden layers and a output layer. \n",
    "- The 2 `hidden layers` `(linear layers)` are going to have `16 units` each followed by a `ReLU` activation layer and the `output layer` `(linear layer)` is going to have `1 unit` followed by a `Sigmoid` unit. \n",
    "- The output layer is going to predict the `probability` of wether the given input is either a `0` or a `1`. If the predicted probability is `> 0.5 we` will assumse that the `predicted output` is `1` else `0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assemble the layers required to construct out model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**These are our inputs and targets:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Inputs: (10610, 784)\n",
      "Shape of Targets: (10610, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#collapse\n",
    "print(\"Shape of Inputs:\", x_train.shape)\n",
    "print(\"Shape of Targets:\", y_train.shape)\n",
    "\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "for i in range(10):\n",
    "    n = np.random.randint(len(x_train))\n",
    "    val = x_train[n]\n",
    "    ax = plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(val.reshape(28,28), cmap=\"binary\")\n",
    "    plt.title(f\"Target value: {y_train[n].squeeze()}\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize model parameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784, 16), (1, 16), (16, 16), (1, 16), (16, 1), (1, 1))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_output\n",
    "\n",
    "nh1 = 16 # no. of units in the first hidden layer\n",
    "nh2 = 16 # no. of units in the 2nd hidden layer\n",
    "nh3 = 1 # no. of units in the output layer\n",
    "\n",
    "w1  = np.random.randn(x_train.shape[1], nh1) * 0.01\n",
    "b1  = np.zeros((1, nh1))\n",
    "\n",
    "w2  = np.random.randn(nh1, nh2) * 0.01\n",
    "b2  = np.zeros((1, nh2))\n",
    "\n",
    "w3  = np.random.randn(nh2, nh3)\n",
    "b3  = np.zeros((1, nh3))\n",
    "\n",
    "w1.shape, b1.shape, w2.shape, b2.shape, w3.shape, b3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instaniating the layers needed to construct our model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin1    = Linear(w1,b1) # 1 hidden layer\n",
    "relu1   = RelU()\n",
    "lin2    = Linear(w2,b2) # 2nd hidden layer\n",
    "relu2   = RelU()\n",
    "lin3    = Linear(w3,b3) # output layer\n",
    "sigmoid = Sigmoid()\n",
    "\n",
    "loss_fn = CELoss() # loss_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6914281432245456\n"
     ]
    }
   ],
   "source": [
    "# forward pass\n",
    "z1   = lin1.forward(x_train)\n",
    "a1   = relu1.forward(z1)\n",
    "z2   = lin2.forward(a1)\n",
    "a2   = relu2.forward(z2)\n",
    "z3   = lin3.forward(a2)\n",
    "pred = a3 = sigmoid.forward(z3)\n",
    "\n",
    "# calculate loss\n",
    "loss = loss_fn.forward(pred, y_train)\n",
    "print(\"Loss:\", loss) # print out the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward pass\n",
    "da3 = loss_fn.backward() # gradient of loss wrt to final output\n",
    "dz3 = sigmoid.backward(da3)\n",
    "\n",
    "da2, dw3, db3 = lin3.backward(dz3)\n",
    "\n",
    "dz2 = relu2.backward(da2)\n",
    "da1, dw2, db2 = lin2.backward(dz2)\n",
    "\n",
    "dz1 = relu1.backward(da1)\n",
    "_, dw1, db1 = lin1.backward(da1)\n",
    "\n",
    "# check if the parameters and the gradients are of same shape\n",
    "# so that we can preform the update state\n",
    "assert lin1.w.shape == dw1.shape\n",
    "assert lin2.w.shape == dw2.shape\n",
    "assert lin3.w.shape == dw3.shape\n",
    "\n",
    "assert lin1.b.shape == db1.shape\n",
    "assert lin2.b.shape == db2.shape\n",
    "assert lin3.b.shape == db3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set learning rate\n",
    "learning_rate = 0.0002\n",
    "\n",
    "# update parameters \n",
    "lin1.w -= learning_rate * dw1\n",
    "lin2.w -= learning_rate * dw2\n",
    "lin3.w -= learning_rate * dw3\n",
    "\n",
    "lin1.b -= learning_rate * db1\n",
    "lin2.b -= learning_rate * db2\n",
    "lin3.b -= learning_rate * db3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, this is how our training our model is going to look we first calculate the `loss` of the model during the `forward pass` , then we calculate the gradients of the `loss` wrt to the `parameters` of the model. After which these `gradients` are used to `update the model parameters`. We continue this workflow for a certain number of `iterations` or until our `loss` reaches the desired value.\n",
    "\n",
    "Let's code up a class which will make this steps easir to achieve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Initializing parameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784, 16), (1, 16), (16, 16), (1, 16), (16, 1), (1, 1))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_output\n",
    "\n",
    "# Instantiate parameters\n",
    "nh1 = 16 # no. of units in the first hidden layer\n",
    "nh2 = 16 # no. of units in the 2nd hidden layer\n",
    "nh3 = 1 # no. of units in the output layer\n",
    "\n",
    "w1  = np.random.randn(x_train.shape[1], nh1) * 0.01\n",
    "b1  = np.zeros((1, nh1))\n",
    "\n",
    "w2  = np.random.randn(nh1, nh2) * 0.01\n",
    "b2  = np.zeros((1, nh2))\n",
    "\n",
    "w3  = np.random.randn(nh2, nh3)\n",
    "b3  = np.zeros((1, nh3))\n",
    "\n",
    "w1.shape, b1.shape, w2.shape, b2.shape, w3.shape, b3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our convenice, we will create a `Model` class . \n",
    "\n",
    "This `Model` class will store all the parameters for our neural-network.\n",
    "The `forward` method will compute the `forward pass` of the network to generate the `loss` (and or `predictions`) of the model. The `backward` method will compute the `backward pass` of the network to get the gradinets of the `loss` wrt to the `parameters` of the model. Finally the `update` method will update the parameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, learning_rate):\n",
    "        \"\"\"\n",
    "        A simple neural network model\n",
    "        The `forward` method computes the forward propagation step of the model\n",
    "        The `backward` method computes the backward step propagation of the model\n",
    "        The `update_step` method updates the parameters of the model\n",
    "        \"\"\"\n",
    "        self.lin1    = Linear(w1,b1) # 1st linear layer\n",
    "        self.relu1   = RelU()        # 1st activation layer\n",
    "        self.lin2    = Linear(w2,b2) # 2nd linear layer\n",
    "        self.relu2   = RelU()        # 2nd activation layer\n",
    "        self.lin3    = Linear(w3,b3) # 3rd linear layer\n",
    "        self.sigmoid = Sigmoid()     # 3rd activation layer\n",
    "        self.loss_fn = CELoss()      # loss_fn\n",
    "        \n",
    "        # learning_rate to update model parameters\n",
    "        self.lr      = learning_rate\n",
    "        # stores the loss at each iteration\n",
    "        self.losses  = [] \n",
    "\n",
    "\n",
    "    def forward(self, inp, calc_loss=True, targ=None):\n",
    "        \"\"\"\n",
    "        Computs the forward step for out model Additionally\n",
    "        it also returns the loss [Optional] and the predictions\n",
    "        of the model.\n",
    "        \n",
    "        Args:\n",
    "            inp       : the training set.\n",
    "            calc_loss : wether to calculate loss of the model if False only predictions\n",
    "                        are calculated.\n",
    "            targ      : the original targets to the training set. \n",
    "        \n",
    "        Note: to calculate the `loss` the `targ` must be given\n",
    "        \n",
    "        Returns:\n",
    "            pred : outputs of the 3rd activation layer.\n",
    "            loss : [Optional] loss the model , if the `targ` is given.\n",
    "        \"\"\"\n",
    "        out  = self.relu1.forward(self.lin1.forward(inp))\n",
    "        out  = self.relu2.forward(self.lin2.forward(out))\n",
    "        pred = self.sigmoid.forward(self.lin3.forward(out))\n",
    "        \n",
    "        if calc_loss:\n",
    "            assert targ is not None, \"to calculate loss targets must be given\"\n",
    "            loss = self.loss_fn.forward(pred, targ)\n",
    "            # appending the loss of the current iteration\n",
    "            self.losses.append(loss)\n",
    "            return loss, pred\n",
    "        else:\n",
    "            return pred\n",
    "        \n",
    "    def _assert_shapes(self):\n",
    "        \"\"\"\n",
    "        Checks the shape of the parameters and the gradients of the model\n",
    "        \"\"\"\n",
    "        assert lin1.w.shape == dw1.shape\n",
    "        assert lin2.w.shape == dw2.shape\n",
    "        assert lin3.w.shape == dw3.shape\n",
    "\n",
    "        assert lin1.b.shape == db1.shape\n",
    "        assert lin2.b.shape == db2.shape\n",
    "        assert lin3.b.shape == db3.shape\n",
    "\n",
    "\n",
    "    def backward(self):\n",
    "        \"\"\"\n",
    "        Computes the backward step\n",
    "        and return the gradients of the parameters with the loss\n",
    "        \"\"\"\n",
    "        da3 = self.loss_fn.backward()\n",
    "        dz3 = self.sigmoid.backward(da3)\n",
    "        da2, dw3, db3 = self.lin3.backward(dz3)\n",
    "        \n",
    "        dz2 = self.relu2.backward(da2)\n",
    "        da1, dw2, db2 = self.lin2.backward(dz2)\n",
    "\n",
    "        dz1 = self.relu1.backward(da1)\n",
    "        _, dw1, db1 = self.lin1.backward(dz1)\n",
    "        \n",
    "        self._assert_shapes()\n",
    "\n",
    "        self.dws = [dw1, dw2, dw3]\n",
    "        self.dbs = [db1, db2, db3]\n",
    "\n",
    "\n",
    "    def update(self):\n",
    "        \"\"\"\n",
    "        Performs the update step\n",
    "        \"\"\"\n",
    "        self.lin1.w -= self.lr * self.dws[0]\n",
    "        self.lin2.w -= self.lr * self.dws[1]\n",
    "        self.lin3.w -= self.lr * self.dws[2]\n",
    "\n",
    "        self.lin1.b -= self.lr * self.dbs[0]\n",
    "        self.lin2.b -= self.lr * self.dbs[1]\n",
    "        self.lin3.b -= self.lr * self.dbs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after interation 0 is 0.6924\n",
      "Loss after interation 1 is 0.6900\n",
      "Loss after interation 2 is 0.6859\n",
      "Loss after interation 3 is 0.6826\n",
      "Loss after interation 4 is 0.6760\n",
      "Loss after interation 5 is 0.6683\n",
      "Loss after interation 6 is 0.6565\n",
      "Loss after interation 7 is 0.6415\n",
      "Loss after interation 8 is 0.6190\n",
      "Loss after interation 9 is 0.5894\n",
      "Loss after interation 10 is 0.5532\n",
      "Loss after interation 11 is 0.5110\n",
      "Loss after interation 12 is 0.4643\n",
      "Loss after interation 13 is 0.4128\n",
      "Loss after interation 14 is 0.3635\n",
      "Loss after interation 15 is 0.3164\n",
      "Loss after interation 16 is 0.2747\n",
      "Loss after interation 17 is 0.2389\n",
      "Loss after interation 18 is 0.2086\n",
      "Loss after interation 19 is 0.1834\n",
      "Loss after interation 20 is 0.1624\n",
      "Loss after interation 21 is 0.1448\n",
      "Loss after interation 22 is 0.1300\n",
      "Loss after interation 23 is 0.1174\n",
      "Loss after interation 24 is 0.1068\n",
      "Loss after interation 25 is 0.0976\n",
      "Loss after interation 26 is 0.0897\n",
      "Loss after interation 27 is 0.0828\n",
      "Loss after interation 28 is 0.0769\n",
      "Loss after interation 29 is 0.0716\n",
      "Loss after interation 30 is 0.0670\n",
      "Loss after interation 31 is 0.0628\n",
      "Loss after interation 32 is 0.0591\n",
      "Loss after interation 33 is 0.0559\n",
      "Loss after interation 34 is 0.0529\n",
      "Loss after interation 35 is 0.0502\n",
      "Loss after interation 36 is 0.0478\n",
      "Loss after interation 37 is 0.0456\n",
      "Loss after interation 38 is 0.0436\n",
      "Loss after interation 39 is 0.0417\n",
      "Loss after interation 40 is 0.0400\n",
      "Loss after interation 41 is 0.0384\n",
      "Loss after interation 42 is 0.0370\n",
      "Loss after interation 43 is 0.0357\n",
      "Loss after interation 44 is 0.0344\n",
      "Loss after interation 45 is 0.0333\n",
      "Loss after interation 46 is 0.0322\n",
      "Loss after interation 47 is 0.0312\n",
      "Loss after interation 48 is 0.0302\n",
      "Loss after interation 49 is 0.0294\n",
      "Loss after interation 50 is 0.0285\n",
      "Loss after interation 51 is 0.0278\n",
      "Loss after interation 52 is 0.0270\n",
      "Loss after interation 53 is 0.0263\n",
      "Loss after interation 54 is 0.0257\n",
      "Loss after interation 55 is 0.0251\n",
      "Loss after interation 56 is 0.0245\n",
      "Loss after interation 57 is 0.0239\n",
      "Loss after interation 58 is 0.0234\n",
      "Loss after interation 59 is 0.0229\n"
     ]
    }
   ],
   "source": [
    "nn = Model(learning_rate=0.0005)\n",
    "epochs = 60 # no. of iterations to train\n",
    "\n",
    "for n in range(epochs):\n",
    "    loss, _ = nn.forward(x_train, calc_loss=True, targ=y_train)\n",
    "    nn.backward()\n",
    "    nn.update()\n",
    "    print(f\"Loss after interation {n} is {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#collapse\n",
    "plt.plot(nn.losses, color=\"teal\")\n",
    "plt.title(\"Loss per Iteration\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing accuracy of our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's check our model performance by computing the `accuracy` on the `validation` dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_accuracy(preds, targs):\n",
    "    \"\"\"\n",
    "    Fn that computes the accuracy between the predicted values and the targets\n",
    "    \"\"\"\n",
    "    m = len(targs)\n",
    "    p = np.zeros_like(preds)\n",
    "    # convert probas to 0/1 predictions\n",
    "    for i in range(len(preds)):\n",
    "        if preds[i] > 0.5:\n",
    "            p[i] = 1\n",
    "        else:\n",
    "            p[i] = 0\n",
    "    print(\"Accuracy: \"  + str(np.sum((p == targs)/m)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "computing accuracy on the train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9971724787935912\n"
     ]
    }
   ],
   "source": [
    "preds = nn.forward(x_train, calc_loss=False) # generate predictions from our model\n",
    "# compute accuracy\n",
    "comp_accuracy(preds, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "computing accuracy on the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9980535279805351\n"
     ]
    }
   ],
   "source": [
    "preds = nn.forward(x_valid, calc_loss=False) # generate predictions from our model\n",
    "# compute accuracy\n",
    "comp_accuracy(preds, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: our model achieved a `accuracy` of **`0.99`** on both the `train` and the `validation` set !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating predictions from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted output: 0\n"
     ]
    }
   ],
   "source": [
    "#collapse\n",
    "test_inp = x_valid[0] # one example from the validation set\n",
    "plt.title(\"Input: \")\n",
    "\n",
    "plt.imshow(test_inp.reshape(28,28), cmap=\"binary\")\n",
    "plt.show()\n",
    "\n",
    "pred = nn.forward(test_inp, calc_loss=False)\n",
    "predicted_val = int(pred > 0.5)\n",
    "print(f\"Predicted output: {predicted_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted output: 1\n"
     ]
    }
   ],
   "source": [
    "#collapse\n",
    "test_inp = x_valid[2000] # one example from the validation set\n",
    "plt.title(\"Input: \")\n",
    "plt.imshow(test_inp.reshape(28,28), cmap=\"binary\")\n",
    "plt.show()\n",
    "\n",
    "pred = nn.forward(test_inp, calc_loss=False)\n",
    "predicted_val = int(pred > 0.5)\n",
    "print(f\"Predicted output: {predicted_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We were able to create a model that can identify classify handwritten digits as either 1's or 0's\n",
    "- We successfully computed the `forward` and `backward` progation of a `neural network` from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thanks for reading !**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
