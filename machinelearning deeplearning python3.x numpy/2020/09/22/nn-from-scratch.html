<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Creating a Neural-Network from scratch | Another Deep-Learning Blog</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Creating a Neural-Network from scratch" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A tutorial to code a neural network from scratch in python using numpy." />
<meta property="og:description" content="A tutorial to code a neural network from scratch in python using numpy." />
<link rel="canonical" href="https://benihime91.github.io/blog/machinelearning%20deeplearning%20python3.x%20numpy/2020/09/22/nn-from-scratch.html" />
<meta property="og:url" content="https://benihime91.github.io/blog/machinelearning%20deeplearning%20python3.x%20numpy/2020/09/22/nn-from-scratch.html" />
<meta property="og:site_name" content="Another Deep-Learning Blog" />
<meta property="og:image" content="https://benihime91.github.io/blog/images/backprop.jpeg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-09-22T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"A tutorial to code a neural network from scratch in python using numpy.","url":"https://benihime91.github.io/blog/machinelearning%20deeplearning%20python3.x%20numpy/2020/09/22/nn-from-scratch.html","@type":"BlogPosting","headline":"Creating a Neural-Network from scratch","dateModified":"2020-09-22T00:00:00-05:00","datePublished":"2020-09-22T00:00:00-05:00","image":"https://benihime91.github.io/blog/images/backprop.jpeg","mainEntityOfPage":{"@type":"WebPage","@id":"https://benihime91.github.io/blog/machinelearning%20deeplearning%20python3.x%20numpy/2020/09/22/nn-from-scratch.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://benihime91.github.io/blog/feed.xml" title="Another Deep-Learning Blog" /><link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Another Deep-Learning Blog</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Creating a Neural-Network from scratch</h1><p class="page-description">A tutorial to code a neural network from scratch in python using numpy.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-09-22T00:00:00-05:00" itemprop="datePublished">
        Sep 22, 2020
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      20 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#machinelearning deeplearning python3.x numpy">machinelearning deeplearning python3.x numpy</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/benihime91/blog/tree/master/_notebooks/2020-09-22-nn-from-scratch.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/benihime91/blog/master?filepath=_notebooks%2F2020-09-22-nn-from-scratch.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/benihime91/blog/blob/master/_notebooks/2020-09-22-nn-from-scratch.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-09-22-nn-from-scratch.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I will assume that you all know what a artificial neural network is and have a little bit of knowledge about <code>forward and backward propagation</code>. Just having a simple idea is enough.
<div class="flash flash-success">
    <svg class="octicon octicon-checklist octicon octicon-checklist" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M2.5 1.75a.25.25 0 01.25-.25h8.5a.25.25 0 01.25.25v7.736a.75.75 0 101.5 0V1.75A1.75 1.75 0 0011.25 0h-8.5A1.75 1.75 0 001 1.75v11.5c0 .966.784 1.75 1.75 1.75h3.17a.75.75 0 000-1.5H2.75a.25.25 0 01-.25-.25V1.75zM4.75 4a.75.75 0 000 1.5h4.5a.75.75 0 000-1.5h-4.5zM4 7.75A.75.75 0 014.75 7h2a.75.75 0 010 1.5h-2A.75.75 0 014 7.75zm11.774 3.537a.75.75 0 00-1.048-1.074L10.7 14.145 9.281 12.72a.75.75 0 00-1.062 1.058l1.943 1.95a.75.75 0 001.055.008l4.557-4.45z"></path></svg>
    <strong>Tip: </strong>If you do not know what the above terms are or would like to brush up on the topics, I would suggest going through this amazing <a href="https://www.youtube.com/watch?v=aircAruvnKk&amp;list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi">youtube playlist</a> by <a href="https://www.3blue1brown.com/">3Blue1Brown</a>.
</div></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>
<center>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/watch?v=aircAruvnKk&amp;list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi" frameborder="0" allowfullscreen=""></iframe>
</center>
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Setting-up-Imports:">Setting up Imports:<a class="anchor-link" href="#Setting-up-Imports:"> </a></h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">gzip</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Preparing-the-data">Preparing the data<a class="anchor-link" href="#Preparing-the-data"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For this blog post, we'll use one of the most famous datasets in computer vision, <a href="https://en.wikipedia.org/wiki/MNIST_database">MNIST</a>. MNIST contains images of handwritten digits, collected by the National Institute of Standards and Technology and collated into a machine learning dataset by Yann Lecun and his colleagues. Lecun used MNIST in 1998 in <a href="http://yann.lecun.com/exdb/lenet/">Lenet-5</a>, the first computer system to demonstrate practically useful recognition of handwritten digit sequences. This was one of the most important breakthroughs in the history of AI.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Run the code given below to download the <code>MNIST</code> dataset.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="highlight"><pre><span></span>wget -P path http://deeplearning.net/data/mnist/mnist.pkl.gz
</pre></div>
<p><div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>the above code snippet will download the dataset to <code>{path}</code> so be sure to set the <code>{path}</code> to the desired location of your choice. 
</div></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_data</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fn to unzip the MNIST data and return</span>
<span class="sd">    the data as numpy arrays</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">gzip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="p">((</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">),</span> <span class="n">_</span><span class="p">)</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;latin-1&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">map</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> <span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">x_valid</span><span class="p">,</span><span class="n">y_valid</span><span class="p">))</span>


<span class="c1"># Grab the MNIST dataset</span>
<span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">x_valid</span><span class="p">,</span><span class="n">y_valid</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="n">path</span><span class="o">=</span> <span class="s2">&quot;../../Datasets/mnist.pkl.gz&quot;</span><span class="p">)</span>

<span class="n">tots</span><span class="p">,</span><span class="n">feats</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">shape</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of x_train:&quot;</span><span class="p">,</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total number of examples:&quot;</span><span class="p">,</span> <span class="n">tots</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of pixel values per image:&quot;</span><span class="p">,</span> <span class="n">feats</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Shape of x_train: (50000, 784)
Total number of examples: 50000
Number of pixel values per image: 784
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Preparing-our-train-&amp;-validation-datasets">Preparing our <code>train</code> &amp; <code>validation</code> datasets<a class="anchor-link" href="#Preparing-our-train-&amp;-validation-datasets"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To make our life a bit easier we are going to take only the examples that contain a 1 or 0.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">zero_mask</span> <span class="o">=</span> <span class="p">[</span><span class="n">y_train</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># grab all the index values where 0 is present</span>
<span class="n">one_mask</span> <span class="o">=</span> <span class="p">[</span><span class="n">y_train</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># grad all the index valus where 1 is present</span>

<span class="c1"># grab all the 1&#39;s and 0&#39;s and make training set</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">x_train</span><span class="p">[</span><span class="n">zero_mask</span><span class="p">],</span> <span class="n">x_train</span><span class="p">[</span><span class="n">one_mask</span><span class="p">]))</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">y_train</span><span class="p">[</span><span class="n">zero_mask</span><span class="p">],</span> <span class="n">y_train</span><span class="p">[</span><span class="n">one_mask</span><span class="p">])))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>

<span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>((10610, 784), (10610, 1))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Our training set now has 10610 examples</strong></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">zero_mask</span> <span class="o">=</span> <span class="p">[</span><span class="n">y_valid</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># grab all the index values where 0 is present</span>
<span class="n">one_mask</span> <span class="o">=</span> <span class="p">[</span><span class="n">y_valid</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># grad all the index valus where 1 is present</span>

<span class="c1"># grab all the 1&#39;s and 0&#39;s and make training set</span>
<span class="n">x_valid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">x_valid</span><span class="p">[</span><span class="n">zero_mask</span><span class="p">],</span> <span class="n">x_valid</span><span class="p">[</span><span class="n">one_mask</span><span class="p">]))</span>
<span class="n">y_valid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">y_valid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">y_valid</span><span class="p">[</span><span class="n">zero_mask</span><span class="p">],</span> <span class="n">y_valid</span><span class="p">[</span><span class="n">one_mask</span><span class="p">])))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>

<span class="n">x_valid</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_valid</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>((2055, 784), (2055, 1))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Our validation set now has 2055 examples</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Why do we need different training and validation sets ?</strong></p>
<p>Since, this topic requires a different post on it's own I won't be covering it here. But you can get the idea from this above video:

<center>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/1waHlpKiNyY?t=243" frameborder="0" allowfullscreen=""></iframe>
</center>
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's view some example images from our dataset:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p><div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">x_train</span><span class="p">[</span><span class="mi">50</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>
</p>
    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p><div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">x_train</span><span class="p">[</span><span class="mi">5000</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>
</p>
    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Basic-Model-Architecture">Basic Model Architecture<a class="anchor-link" href="#Basic-Model-Architecture"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For this task we are going to use a very basic model architecture this 2 linear layers and a output layer with 1 unit.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Let's-take-a-deep-dive-into-what-this-network-means:">Let's take a deep dive into what this network means:<a class="anchor-link" href="#Let's-take-a-deep-dive-into-what-this-network-means:"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's take at look at all the individual components of this network:</p>
<ul>
<li><p><strong>Linear:</strong>
The linear layer computes the following :</p>

<pre><code> out = matmul(input,W1) + B1</code></pre>
</li>
<li><p><strong>ReLU:</strong> 
The relu computes the following:</p>

<pre><code>out = max(0, input)</code></pre>
</li>
<li><p><strong>Sigmoid:</strong> 
The sigmoid computes the following:</p>

<pre><code>out = 1/(1 + e.pow(input))</code></pre>
</li>
<li><p><strong>Loss:</strong> 
For the loss we are going to use the CrossEntropy Loss which is defined by the follwoing equation:
$$loss= -\frac{1}{m} \sum\limits_{i = 1}^{m} (y^{(i)}\log\left(yhat^{(i)}\right) + (1-y^{(i)})\log\left(1-yhat^{(i)}\right)) $$</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Now that we have our model architecture, let's create the different parts needed to assemble the model:</strong></p>
<ul>
<li>linear layer</li>
<li>relu activation</li>
<li>sigmoid activation</li>
<li>loss</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Let's first try to make some sense of what is happening in the backward and forward pass of our model:</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>On paper our forward pass would look something like this:</strong>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong><code>@</code> in python is the <code>matrix-multiplication operator</code>. 
</div></p>
<div class="highlight"><pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="n">x_train</span> <span class="c1"># original inputs</span>
<span class="n">targets</span> <span class="o">=</span> <span class="n">y_train</span> <span class="c1"># original targets</span>

<span class="c1"># forward pass for the 1st linear layer</span>
<span class="n">z1</span> <span class="o">=</span> <span class="n">inputs</span> <span class="o">@</span> <span class="n">w2</span> <span class="o">+</span> <span class="n">b2</span>
<span class="n">a1</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">z1</span><span class="p">)</span>
<span class="c1"># forward pass for the 2nd linear layer</span>
<span class="n">z2</span> <span class="o">=</span> <span class="n">a1</span> <span class="o">@</span> <span class="n">w2</span> <span class="o">+</span> <span class="n">b2</span>
<span class="n">a2</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">z2</span><span class="p">)</span>
<span class="c1"># forward pass for the output linear layer</span>
<span class="n">z3</span> <span class="o">=</span> <span class="n">a2</span> <span class="o">@</span> <span class="n">w3</span> <span class="o">+</span> <span class="n">b3</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">a3</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z3</span><span class="p">)</span> <span class="c1"># these are our model predictions </span>
<span class="c1"># calculate loss between original targets &amp; model predictions</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">a3</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
</pre></div>
<p><div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>This is not actual code it&#8217;s just psuedo-code for understanding.
</div></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Forward pass :</strong></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_svg output_subarea output_execute_result">
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
&lt;!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"&gt;
<!-- Generated by graphviz version 2.44.0 (20200408.0750)
 -->
<!-- Title: G Pages: 1 -->
<svg width="811pt" height="260pt" viewBox="0.00 0.00 810.56 260.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 256)">
<title>G</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-256 806.56,-256 806.56,4 -4,4" />
<!-- X -->
<g id="node1" class="node">
<title>X</title>
<ellipse fill="none" stroke="black" cx="27" cy="-234" rx="27" ry="18" />
<text text-anchor="middle" x="27" y="-230.3" font-family="Times,serif" font-size="14.00">X</text>
</g>
<!-- linear1 -->
<g id="node2" class="node">
<title>linear1</title>
<ellipse fill="none" stroke="black" cx="125.1" cy="-180" rx="35.19" ry="18" />
<text text-anchor="middle" x="125.1" y="-176.3" font-family="Times,serif" font-size="14.00">linear1</text>
</g>
<!-- X&#45;&gt;linear1 -->
<g id="edge1" class="edge">
<title>X&#45;&gt;linear1</title>
<path fill="none" stroke="black" d="M48.38,-222.55C60.94,-215.49 77.34,-206.28 91.66,-198.23" />
<polygon fill="black" stroke="black" points="93.7,-201.1 100.7,-193.15 90.27,-194.99 93.7,-201.1" />
</g>
<!-- relu1 -->
<g id="node3" class="node">
<title>relu1</title>
<ellipse fill="none" stroke="black" cx="224.79" cy="-180" rx="28.7" ry="18" />
<text text-anchor="middle" x="224.79" y="-176.3" font-family="Times,serif" font-size="14.00">relu1</text>
</g>
<!-- linear1&#45;&gt;relu1 -->
<g id="edge2" class="edge">
<title>linear1&#45;&gt;relu1</title>
<path fill="none" stroke="black" d="M160.27,-180C168.56,-180 177.47,-180 185.93,-180" />
<polygon fill="black" stroke="black" points="185.93,-183.5 195.93,-180 185.93,-176.5 185.93,-183.5" />
</g>
<!-- linear2 -->
<g id="node4" class="node">
<title>linear2</title>
<ellipse fill="none" stroke="black" cx="324.49" cy="-126" rx="35.19" ry="18" />
<text text-anchor="middle" x="324.49" y="-122.3" font-family="Times,serif" font-size="14.00">linear2</text>
</g>
<!-- relu1&#45;&gt;linear2 -->
<g id="edge3" class="edge">
<title>relu1&#45;&gt;linear2</title>
<path fill="none" stroke="black" d="M246.99,-168.28C259.79,-161.21 276.36,-152.05 290.81,-144.06" />
<polygon fill="black" stroke="black" points="292.87,-146.92 299.93,-139.02 289.49,-140.79 292.87,-146.92" />
</g>
<!-- relu2 -->
<g id="node5" class="node">
<title>relu2</title>
<ellipse fill="none" stroke="black" cx="424.18" cy="-126" rx="28.7" ry="18" />
<text text-anchor="middle" x="424.18" y="-122.3" font-family="Times,serif" font-size="14.00">relu2</text>
</g>
<!-- linear2&#45;&gt;relu2 -->
<g id="edge4" class="edge">
<title>linear2&#45;&gt;relu2</title>
<path fill="none" stroke="black" d="M359.65,-126C367.95,-126 376.86,-126 385.32,-126" />
<polygon fill="black" stroke="black" points="385.32,-129.5 395.32,-126 385.32,-122.5 385.32,-129.5" />
</g>
<!-- linear3 -->
<g id="node6" class="node">
<title>linear3</title>
<ellipse fill="none" stroke="black" cx="523.87" cy="-72" rx="35.19" ry="18" />
<text text-anchor="middle" x="523.87" y="-68.3" font-family="Times,serif" font-size="14.00">linear3</text>
</g>
<!-- relu2&#45;&gt;linear3 -->
<g id="edge5" class="edge">
<title>relu2&#45;&gt;linear3</title>
<path fill="none" stroke="black" d="M446.38,-114.28C459.18,-107.21 475.75,-98.05 490.2,-90.06" />
<polygon fill="black" stroke="black" points="492.26,-92.92 499.32,-85.02 488.88,-86.79 492.26,-92.92" />
</g>
<!-- sigmoid -->
<g id="node7" class="node">
<title>sigmoid</title>
<ellipse fill="none" stroke="black" cx="634.62" cy="-72" rx="39.79" ry="18" />
<text text-anchor="middle" x="634.62" y="-68.3" font-family="Times,serif" font-size="14.00">sigmoid</text>
</g>
<!-- linear3&#45;&gt;sigmoid -->
<g id="edge6" class="edge">
<title>linear3&#45;&gt;sigmoid</title>
<path fill="none" stroke="black" d="M558.98,-72C567.13,-72 575.99,-72 584.66,-72" />
<polygon fill="black" stroke="black" points="584.7,-75.5 594.7,-72 584.7,-68.5 584.7,-75.5" />
</g>
<!-- prediction -->
<g id="node8" class="node">
<title>prediction</title>
<ellipse fill="none" stroke="black" cx="756.41" cy="-72" rx="46.29" ry="18" />
<text text-anchor="middle" x="756.41" y="-68.3" font-family="Times,serif" font-size="14.00">prediction</text>
</g>
<!-- sigmoid&#45;&gt;prediction -->
<g id="edge7" class="edge">
<title>sigmoid&#45;&gt;prediction</title>
<path fill="none" stroke="black" d="M674.51,-72C682.66,-72 691.41,-72 700.03,-72" />
<polygon fill="black" stroke="black" points="700.05,-75.5 710.05,-72 700.05,-68.5 700.05,-75.5" />
</g>
<!-- W1 -->
<g id="node9" class="node">
<title>W1</title>
<ellipse fill="none" stroke="black" cx="27" cy="-180" rx="27" ry="18" />
<text text-anchor="middle" x="27" y="-176.3" font-family="Times,serif" font-size="14.00">W1</text>
</g>
<!-- W1&#45;&gt;linear1 -->
<g id="edge8" class="edge">
<title>W1&#45;&gt;linear1</title>
<path fill="none" stroke="black" d="M54.01,-180C61.92,-180 70.84,-180 79.61,-180" />
<polygon fill="black" stroke="black" points="79.76,-183.5 89.76,-180 79.76,-176.5 79.76,-183.5" />
</g>
<!-- B1 -->
<g id="node10" class="node">
<title>B1</title>
<ellipse fill="none" stroke="black" cx="27" cy="-126" rx="27" ry="18" />
<text text-anchor="middle" x="27" y="-122.3" font-family="Times,serif" font-size="14.00">B1</text>
</g>
<!-- B1&#45;&gt;linear1 -->
<g id="edge9" class="edge">
<title>B1&#45;&gt;linear1</title>
<path fill="none" stroke="black" d="M48.38,-137.45C60.94,-144.51 77.34,-153.72 91.66,-161.77" />
<polygon fill="black" stroke="black" points="90.27,-165.01 100.7,-166.85 93.7,-158.9 90.27,-165.01" />
</g>
<!-- W2 -->
<g id="node11" class="node">
<title>W2</title>
<ellipse fill="none" stroke="black" cx="224.79" cy="-126" rx="27" ry="18" />
<text text-anchor="middle" x="224.79" y="-122.3" font-family="Times,serif" font-size="14.00">W2</text>
</g>
<!-- W2&#45;&gt;linear2 -->
<g id="edge10" class="edge">
<title>W2&#45;&gt;linear2</title>
<path fill="none" stroke="black" d="M251.97,-126C260.27,-126 269.68,-126 278.89,-126" />
<polygon fill="black" stroke="black" points="279.14,-129.5 289.14,-126 279.14,-122.5 279.14,-129.5" />
</g>
<!-- B2 -->
<g id="node12" class="node">
<title>B2</title>
<ellipse fill="none" stroke="black" cx="224.79" cy="-72" rx="27" ry="18" />
<text text-anchor="middle" x="224.79" y="-68.3" font-family="Times,serif" font-size="14.00">B2</text>
</g>
<!-- B2&#45;&gt;linear2 -->
<g id="edge11" class="edge">
<title>B2&#45;&gt;linear2</title>
<path fill="none" stroke="black" d="M246.03,-83.19C258.99,-90.35 276.1,-99.81 290.94,-108.01" />
<polygon fill="black" stroke="black" points="289.38,-111.15 299.83,-112.92 292.77,-105.02 289.38,-111.15" />
</g>
<!-- W3 -->
<g id="node13" class="node">
<title>W3</title>
<ellipse fill="none" stroke="black" cx="424.18" cy="-72" rx="27" ry="18" />
<text text-anchor="middle" x="424.18" y="-68.3" font-family="Times,serif" font-size="14.00">W3</text>
</g>
<!-- W3&#45;&gt;linear3 -->
<g id="edge12" class="edge">
<title>W3&#45;&gt;linear3</title>
<path fill="none" stroke="black" d="M451.36,-72C459.66,-72 469.07,-72 478.28,-72" />
<polygon fill="black" stroke="black" points="478.53,-75.5 488.53,-72 478.53,-68.5 478.53,-75.5" />
</g>
<!-- B3 -->
<g id="node14" class="node">
<title>B3</title>
<ellipse fill="none" stroke="black" cx="424.18" cy="-18" rx="27" ry="18" />
<text text-anchor="middle" x="424.18" y="-14.3" font-family="Times,serif" font-size="14.00">B3</text>
</g>
<!-- B3&#45;&gt;linear3 -->
<g id="edge13" class="edge">
<title>B3&#45;&gt;linear3</title>
<path fill="none" stroke="black" d="M445.42,-29.19C458.38,-36.35 475.49,-45.81 490.33,-54.01" />
<polygon fill="black" stroke="black" points="488.77,-57.15 499.22,-58.92 492.16,-51.02 488.77,-57.15" />
</g>
</g>
</svg>

</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_svg output_subarea output_execute_result">
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
&lt;!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"&gt;
<!-- Generated by graphviz version 2.44.0 (20200408.0750)
 -->
<!-- Title: G Pages: 1 -->
<svg width="299pt" height="98pt" viewBox="0.00 0.00 299.09 98.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 94)">
<title>G</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-94 295.09,-94 295.09,4 -4,4" />
<!-- prediction -->
<g id="node1" class="node">
<title>prediction</title>
<ellipse fill="none" stroke="black" cx="46.15" cy="-72" rx="46.29" ry="18" />
<text text-anchor="middle" x="46.15" y="-68.3" font-family="Times,serif" font-size="14.00">prediction</text>
</g>
<!-- loss_fn -->
<g id="node2" class="node">
<title>loss_fn</title>
<ellipse fill="none" stroke="black" cx="164.69" cy="-45" rx="36.29" ry="18" />
<text text-anchor="middle" x="164.69" y="-41.3" font-family="Times,serif" font-size="14.00">loss_fn</text>
</g>
<!-- prediction&#45;&gt;loss_fn -->
<g id="edge1" class="edge">
<title>prediction&#45;&gt;loss_fn</title>
<path fill="none" stroke="black" d="M86.28,-62.93C97.63,-60.3 110.08,-57.42 121.6,-54.75" />
<polygon fill="black" stroke="black" points="122.49,-58.14 131.45,-52.47 120.91,-51.32 122.49,-58.14" />
</g>
<!-- loss -->
<g id="node4" class="node">
<title>loss</title>
<ellipse fill="none" stroke="black" cx="264.09" cy="-45" rx="27" ry="18" />
<text text-anchor="middle" x="264.09" y="-41.3" font-family="Times,serif" font-size="14.00">loss</text>
</g>
<!-- loss_fn&#45;&gt;loss -->
<g id="edge3" class="edge">
<title>loss_fn&#45;&gt;loss</title>
<path fill="none" stroke="black" d="M201.13,-45C209.46,-45 218.36,-45 226.74,-45" />
<polygon fill="black" stroke="black" points="226.99,-48.5 236.99,-45 226.99,-41.5 226.99,-48.5" />
</g>
<!-- target -->
<g id="node3" class="node">
<title>target</title>
<ellipse fill="none" stroke="black" cx="46.15" cy="-18" rx="30.59" ry="18" />
<text text-anchor="middle" x="46.15" y="-14.3" font-family="Times,serif" font-size="14.00">target</text>
</g>
<!-- target&#45;&gt;loss_fn -->
<g id="edge2" class="edge">
<title>target&#45;&gt;loss_fn</title>
<path fill="none" stroke="black" d="M74.76,-24.4C88.68,-27.62 105.85,-31.6 121.39,-35.2" />
<polygon fill="black" stroke="black" points="120.78,-38.65 131.31,-37.5 122.36,-31.83 120.78,-38.65" />
</g>
</g>
</svg>

</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Consequently our backward pass would look something like this :</strong></p>
<p>(Let us assume that the <code>grad(inp, out)</code> computes the gradients of <code>inp</code> wrt <code>out</code>)</p>
<div class="highlight"><pre><span></span><span class="c1"># gradient of loss wrt to the output of the last activation layer: (a3)</span>
<span class="c1"># (or the predictions of model)</span>
<span class="n">da3</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">a3</span><span class="p">)</span>

<span class="c1"># gradient of loss wrt to the output of the current linear layer: (z3)</span>
<span class="n">dz3</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">z3</span><span class="p">)</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">a3</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">a3</span><span class="p">,</span> <span class="n">z3</span><span class="p">)</span>
<span class="c1"># gradient of loss wrt to w3</span>
<span class="n">dw3</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">w3</span><span class="p">)</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">z3</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">z3</span><span class="p">,</span> <span class="n">w3</span><span class="p">)</span> <span class="o">=</span> <span class="n">dz3</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">z3</span><span class="p">,</span> <span class="n">w3</span><span class="p">)</span>
<span class="c1"># gradient of loss wrt to b3</span>
<span class="n">db3</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">b3</span><span class="p">)</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">z3</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">z3</span><span class="p">,</span> <span class="n">b3</span><span class="p">)</span> <span class="o">=</span> <span class="n">dz3</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">z3</span><span class="p">,</span> <span class="n">b3</span><span class="p">)</span>
<span class="c1"># gradient of loss wrt to the input of the current linear layer: (a2)</span>
<span class="n">da2</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">a2</span><span class="p">)</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">a3</span><span class="p">)</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">a2</span><span class="p">,</span> <span class="p">)</span>

<span class="c1"># gradient of loss wrt to the output of the current linear layer: (z2)</span>
<span class="n">dz2</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">z2</span><span class="p">)</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">a2</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">a2</span><span class="p">,</span> <span class="n">z2</span><span class="p">)</span> 
<span class="c1"># gradient of loss wrt to w2</span>
<span class="n">dw2</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">w2</span><span class="p">)</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">z2</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">z2</span><span class="p">,</span> <span class="n">w2</span><span class="p">)</span> <span class="o">=</span> <span class="n">dz2</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">z2</span><span class="p">,</span> <span class="n">w2</span><span class="p">)</span>
<span class="c1"># gradient of loss wrt to b2</span>
<span class="n">db2</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">b2</span><span class="p">)</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">z2</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">z2</span><span class="p">,</span> <span class="n">b2</span><span class="p">)</span> <span class="o">=</span> <span class="n">dz2</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">z2</span><span class="p">,</span> <span class="n">b2</span><span class="p">)</span>
<span class="c1"># gradient of loss wrt to the input of the current linear layer: (a1)</span>
<span class="n">da1</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">a1</span><span class="p">)</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">z2</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">z2</span><span class="p">,</span> <span class="n">a1</span><span class="p">)</span> <span class="o">=</span> <span class="n">dz2</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">z2</span><span class="p">,</span> <span class="n">a1</span><span class="p">)</span>

<span class="c1"># gradient of loss wrt to the output of the current linear layer: (z1)</span>
<span class="n">dz1</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">z1</span><span class="p">)</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">a1</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">a1</span><span class="p">,</span> <span class="n">z1</span><span class="p">)</span> <span class="o">=</span> <span class="n">da1</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">a1</span><span class="p">,</span> <span class="n">z1</span><span class="p">)</span>
<span class="c1"># gradient of loss wrt to w1</span>
<span class="n">dw1</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">w1</span><span class="p">)</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">z1</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">z1</span><span class="p">,</span> <span class="n">w1</span><span class="p">)</span> <span class="o">=</span> <span class="n">dz1</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">z1</span><span class="p">,</span> <span class="n">w1</span><span class="p">)</span>
<span class="c1"># gradient of loss wrt to b1</span>
<span class="n">db1</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">b1</span><span class="p">)</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">z1</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">z1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">=</span> <span class="n">dz1</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">z1</span><span class="p">,</span> <span class="n">b1</span><span class="p">)</span>
<span class="c1"># In this layer the inputs are out training examples which we cannot change so</span>
<span class="c1"># we do not need to commpute more gradients</span>

<span class="c1"># Update parameters :</span>
<span class="c1"># since we now have all the required gradients we can now perform the update step</span>
<span class="n">w1</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dw1</span>
<span class="n">b1</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">db1</span>

<span class="n">w2</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dw2</span>
<span class="n">b2</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">db2</span>
</pre></div>
<p><div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>This is not actual code it&#8217;s just psuedo-code for understanding.
</div></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Backward pass:</strong></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_svg output_subarea output_execute_result">
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
&lt;!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"&gt;
<!-- Generated by graphviz version 2.44.0 (20200408.0750)
 -->
<!-- Title: G Pages: 1 -->
<svg width="773pt" height="233pt" viewBox="0.00 0.00 772.86 233.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 229)">
<title>G</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-229 768.86,-229 768.86,4 -4,4" />
<!-- Loss -->
<g id="node1" class="node">
<title>Loss</title>
<ellipse fill="none" stroke="black" cx="27.3" cy="-153" rx="27.1" ry="18" />
<text text-anchor="middle" x="27.3" y="-149.3" font-family="Times,serif" font-size="14.00">Loss</text>
</g>
<!-- sigmoid -->
<g id="node2" class="node">
<title>sigmoid</title>
<ellipse fill="none" stroke="black" cx="130.24" cy="-153" rx="39.79" ry="18" />
<text text-anchor="middle" x="130.24" y="-149.3" font-family="Times,serif" font-size="14.00">sigmoid</text>
</g>
<!-- Loss&#45;&gt;sigmoid -->
<g id="edge1" class="edge">
<title>Loss&#45;&gt;sigmoid</title>
<path fill="none" stroke="black" d="M54.82,-153C62.63,-153 71.43,-153 80.18,-153" />
<polygon fill="black" stroke="black" points="80.36,-156.5 90.36,-153 80.36,-149.5 80.36,-156.5" />
</g>
<!-- linear3 -->
<g id="node3" class="node">
<title>linear3</title>
<ellipse fill="none" stroke="black" cx="240.99" cy="-153" rx="35.19" ry="18" />
<text text-anchor="middle" x="240.99" y="-149.3" font-family="Times,serif" font-size="14.00">linear3</text>
</g>
<!-- sigmoid&#45;&gt;linear3 -->
<g id="edge2" class="edge">
<title>sigmoid&#45;&gt;linear3</title>
<path fill="none" stroke="black" d="M170.19,-153C178.43,-153 187.17,-153 195.59,-153" />
<polygon fill="black" stroke="black" points="195.63,-156.5 205.63,-153 195.63,-149.5 195.63,-156.5" />
</g>
<!-- W3 -->
<g id="node4" class="node">
<title>W3</title>
<ellipse fill="none" stroke="black" cx="340.68" cy="-207" rx="27" ry="18" />
<text text-anchor="middle" x="340.68" y="-203.3" font-family="Times,serif" font-size="14.00">W3</text>
</g>
<!-- linear3&#45;&gt;W3 -->
<g id="edge3" class="edge">
<title>linear3&#45;&gt;W3</title>
<path fill="none" stroke="black" d="M265.63,-166.07C279.07,-173.5 296,-182.86 310.29,-190.75" />
<polygon fill="black" stroke="black" points="308.78,-193.92 319.23,-195.69 312.17,-187.79 308.78,-193.92" />
</g>
<!-- B3 -->
<g id="node5" class="node">
<title>B3</title>
<ellipse fill="none" stroke="black" cx="340.68" cy="-153" rx="27" ry="18" />
<text text-anchor="middle" x="340.68" y="-149.3" font-family="Times,serif" font-size="14.00">B3</text>
</g>
<!-- linear3&#45;&gt;B3 -->
<g id="edge4" class="edge">
<title>linear3&#45;&gt;B3</title>
<path fill="none" stroke="black" d="M276.15,-153C284.93,-153 294.41,-153 303.3,-153" />
<polygon fill="black" stroke="black" points="303.38,-156.5 313.38,-153 303.38,-149.5 303.38,-156.5" />
</g>
<!-- relu2 -->
<g id="node6" class="node">
<title>relu2</title>
<ellipse fill="none" stroke="black" cx="340.68" cy="-99" rx="28.7" ry="18" />
<text text-anchor="middle" x="340.68" y="-95.3" font-family="Times,serif" font-size="14.00">relu2</text>
</g>
<!-- linear3&#45;&gt;relu2 -->
<g id="edge5" class="edge">
<title>linear3&#45;&gt;relu2</title>
<path fill="none" stroke="black" d="M265.63,-139.93C278.88,-132.61 295.54,-123.4 309.69,-115.57" />
<polygon fill="black" stroke="black" points="311.52,-118.57 318.58,-110.67 308.13,-112.44 311.52,-118.57" />
</g>
<!-- linear2 -->
<g id="node7" class="node">
<title>linear2</title>
<ellipse fill="none" stroke="black" cx="440.37" cy="-99" rx="35.19" ry="18" />
<text text-anchor="middle" x="440.37" y="-95.3" font-family="Times,serif" font-size="14.00">linear2</text>
</g>
<!-- relu2&#45;&gt;linear2 -->
<g id="edge6" class="edge">
<title>relu2&#45;&gt;linear2</title>
<path fill="none" stroke="black" d="M369.41,-99C377.36,-99 386.23,-99 394.91,-99" />
<polygon fill="black" stroke="black" points="394.96,-102.5 404.96,-99 394.96,-95.5 394.96,-102.5" />
</g>
<!-- W2 -->
<g id="node8" class="node">
<title>W2</title>
<ellipse fill="none" stroke="black" cx="540.07" cy="-153" rx="27" ry="18" />
<text text-anchor="middle" x="540.07" y="-149.3" font-family="Times,serif" font-size="14.00">W2</text>
</g>
<!-- linear2&#45;&gt;W2 -->
<g id="edge7" class="edge">
<title>linear2&#45;&gt;W2</title>
<path fill="none" stroke="black" d="M465.02,-112.07C478.46,-119.5 495.39,-128.86 509.67,-136.75" />
<polygon fill="black" stroke="black" points="508.17,-139.92 518.61,-141.69 511.56,-133.79 508.17,-139.92" />
</g>
<!-- B2 -->
<g id="node9" class="node">
<title>B2</title>
<ellipse fill="none" stroke="black" cx="540.07" cy="-99" rx="27" ry="18" />
<text text-anchor="middle" x="540.07" y="-95.3" font-family="Times,serif" font-size="14.00">B2</text>
</g>
<!-- linear2&#45;&gt;B2 -->
<g id="edge8" class="edge">
<title>linear2&#45;&gt;B2</title>
<path fill="none" stroke="black" d="M475.54,-99C484.32,-99 493.8,-99 502.69,-99" />
<polygon fill="black" stroke="black" points="502.77,-102.5 512.77,-99 502.77,-95.5 502.77,-102.5" />
</g>
<!-- relu1 -->
<g id="node10" class="node">
<title>relu1</title>
<ellipse fill="none" stroke="black" cx="540.07" cy="-45" rx="28.7" ry="18" />
<text text-anchor="middle" x="540.07" y="-41.3" font-family="Times,serif" font-size="14.00">relu1</text>
</g>
<!-- linear2&#45;&gt;relu1 -->
<g id="edge9" class="edge">
<title>linear2&#45;&gt;relu1</title>
<path fill="none" stroke="black" d="M465.02,-85.93C478.27,-78.61 494.93,-69.4 509.08,-61.57" />
<polygon fill="black" stroke="black" points="510.9,-64.57 517.96,-56.67 507.52,-58.44 510.9,-64.57" />
</g>
<!-- linear1 -->
<g id="node11" class="node">
<title>linear1</title>
<ellipse fill="none" stroke="black" cx="639.76" cy="-45" rx="35.19" ry="18" />
<text text-anchor="middle" x="639.76" y="-41.3" font-family="Times,serif" font-size="14.00">linear1</text>
</g>
<!-- relu1&#45;&gt;linear1 -->
<g id="edge10" class="edge">
<title>relu1&#45;&gt;linear1</title>
<path fill="none" stroke="black" d="M568.8,-45C576.75,-45 585.62,-45 594.3,-45" />
<polygon fill="black" stroke="black" points="594.34,-48.5 604.34,-45 594.34,-41.5 594.34,-48.5" />
</g>
<!-- W1 -->
<g id="node12" class="node">
<title>W1</title>
<ellipse fill="none" stroke="black" cx="737.86" cy="-72" rx="27" ry="18" />
<text text-anchor="middle" x="737.86" y="-68.3" font-family="Times,serif" font-size="14.00">W1</text>
</g>
<!-- linear1&#45;&gt;W1 -->
<g id="edge11" class="edge">
<title>linear1&#45;&gt;W1</title>
<path fill="none" stroke="black" d="M670.9,-53.47C681.08,-56.33 692.51,-59.54 702.96,-62.48" />
<polygon fill="black" stroke="black" points="702.03,-65.85 712.6,-65.19 703.92,-59.11 702.03,-65.85" />
</g>
<!-- B1 -->
<g id="node13" class="node">
<title>B1</title>
<ellipse fill="none" stroke="black" cx="737.86" cy="-18" rx="27" ry="18" />
<text text-anchor="middle" x="737.86" y="-14.3" font-family="Times,serif" font-size="14.00">B1</text>
</g>
<!-- linear1&#45;&gt;B1 -->
<g id="edge12" class="edge">
<title>linear1&#45;&gt;B1</title>
<path fill="none" stroke="black" d="M670.9,-36.53C681.08,-33.67 692.51,-30.46 702.96,-27.52" />
<polygon fill="black" stroke="black" points="703.92,-30.89 712.6,-24.81 702.03,-24.15 703.92,-30.89" />
</g>
</g>
</svg>

</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="The-Linear-Layer">The <code>Linear</code> Layer<a class="anchor-link" href="#The-Linear-Layer"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Below code creates a <code>Linear class</code> which represents a <code>Linear</code> layer in our neural-network. The <code>forward function</code> of the class implements the of the <code>layer's forward propagation</code> &amp; the <code>backward function</code> implements the <code>layers's backward propagation</code>. Let's go to detail into what the code means:</p>
<ul>
<li><strong>Forward:</strong><br />
This part is quite straight-forward it computes the dot-product between the <strong><code>input</code></strong> and the <strong><code>weights</code></strong> &amp; adds the <strong><code>bias</code></strong> term to get <strong><code>z</code></strong>. It also stores all the intermidiate values generated to use in the backward pass.</li>
</ul>
<ul>
<li><strong>Backward:</strong><ul>
<li>The backward method of the class <strong><code>Linear</code></strong> takes in the argument <strong><code>grads</code></strong>. </li>
<li><strong><code>grads</code></strong> is the gradient of the loss wrt to the output of the current linear layer ie., <strong><code>dz</code></strong> if we were to follow the nomenclature of our pseudo-code.</li>
<li>To succesfully compute the backward pass for our linear layer we need the following:<ul>
<li><strong><code>grad(z, w)</code></strong> </li>
<li><strong><code>grad(z, b)</code></strong></li>
<li><strong><code>grad(z, a_prev)</code></strong></li>
</ul>
</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong><code>z</code>, <code>w</code>, <code>b</code>, <code>a_prev</code> are the outputs, weights, bias and input-activations of the Linear layer respectively.
</div></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Linear</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">w</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">b</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inp</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Implement the linear part of a layer&#39;s forward propagation.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            inp : activations from previous layer (or input data)</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>

<span class="sd">            z  : the input of the activation function, also called pre-activation parameter </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inp</span> <span class="o">=</span> <span class="n">inp</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">z</span>   <span class="o">=</span> <span class="n">inp</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">z</span>
    
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">grads</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Implement the linear portion of backward propagation for a single layer.</span>

<span class="sd">        Args:</span>
<span class="sd">            grads :  Gradient of the cost with respect to the linear output. </span>
<span class="sd">                     or the accumulated gradients from the prev layers. </span>
<span class="sd">                     This is used for the chain rule to compute the gradients.</span>
<span class="sd">        Returns:</span>
<span class="sd">            da : Gradient of cost wrt to the activation of the previous layer or the input of the </span>
<span class="sd">                 current layer.</span>
<span class="sd">            dw : Gradient of the cost with respect to W</span>
<span class="sd">            db : Gradient of the cost with respect to b</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">m</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># gradient of loss wrt to the weights</span>
        <span class="n">dw</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">m</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inp</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">grads</span><span class="p">)</span>
        <span class="c1"># gradient of the loss wrt to the bias</span>
        <span class="n">db</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">m</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># gradient of the loss wrt to the input of the linear layer</span>
        <span class="c1"># this is used to continue the chain rule</span>
        <span class="n">da_prev</span> <span class="o">=</span> <span class="n">grads</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="o">.</span><span class="n">T</span> 
        <span class="k">return</span> <span class="p">(</span><span class="n">da_prev</span><span class="p">,</span> <span class="n">dw</span><span class="p">,</span> <span class="n">db</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="The-ReLU-Layer">The <code>ReLU</code> Layer<a class="anchor-link" href="#The-ReLU-Layer"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><strong>Forward</strong>:<br />
The mathematical formula for ReLU is $A = RELU(Z) = max(0, Z)$</li>
<li><strong>Backward</strong>:<br />
During the backward pass the relu accepts the gradients of the <code>loss wrt to the activation</code> i.e, <code>da</code> then computes
the gradients of the <code>loss wrt to the input-of-relu(z)</code> i.e, <code>dz</code>.</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">RelU</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inp</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Implement the RELU function.</span>

<span class="sd">        Args:</span>
<span class="sd">            inp : Output of the linear layer, of any shape</span>

<span class="sd">        Returns:</span>
<span class="sd">            a  : Post-activation parameter, of the same shape as Z</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inp</span> <span class="o">=</span> <span class="n">inp</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inp</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span>
    
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">grads</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Implement the backward propagation for a single RELU unit.</span>

<span class="sd">        Ars:</span>
<span class="sd">            grads : gradients of the loss wrt to the activation output</span>

<span class="sd">        Returns:</span>
<span class="sd">            dz : Gradient of the loss with respect to the input of the activation</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dz</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">dz</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">inp</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="n">dz</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="The-sigmoid-Layer">The <code>sigmoid</code> Layer<a class="anchor-link" href="#The-sigmoid-Layer"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The sigmoid layer functions in exactly the same way as the <code>ReLU</code> layer . The only difference is the forward pass output calculation.</p>
<p>In the <code>sigmoid layer</code>:  $\sigma(Z) = \frac{1}{ 1 + e^{-(W A + b)}}$</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Sigmoid</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inp</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Implements the sigmoid activation in numpy</span>

<span class="sd">        Args:</span>
<span class="sd">            inp: numpy array of any shape</span>

<span class="sd">        Returns:</span>
<span class="sd">            a  : output of sigmoid(z), same shape as inp</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inp</span> <span class="o">=</span> <span class="n">inp</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span>  <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">inp</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span>
    
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">grads</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Implement the backward propagation for a single sigmoid unit.</span>

<span class="sd">        Args:</span>
<span class="sd">            grads : gradients of the loss wrt to the activation output</span>

<span class="sd">        Returns:</span>
<span class="sd">            dz : Gradient of the loss with respect to the input of the activation</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">s</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">inp</span><span class="p">))</span>
        <span class="n">dz</span> <span class="o">=</span> <span class="n">grads</span> <span class="o">*</span> <span class="n">s</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">s</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">dz</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Loss-function-:"><code>Loss</code> function :<a class="anchor-link" href="#Loss-function-:"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For this task we are going to use the <a href="https://en.wikipedia.org/wiki/Cross_entropy">CrossEntropy Loss</a></p>
<p>The <code>forward</code> pass of the CrossEntropy Loss is computed as follows: 

$$loss= -\frac{1}{m} \sum\limits_{i = 1}^{m} (y^{(i)}\log\left(yhat^{(i)}\right) + (1-y^{(i)})\log\left(1-yhat^{(i)}\right)) $$
</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">CELoss</span><span class="p">():</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Implement the CrossEntropy loss function.</span>

<span class="sd">        Args:</span>
<span class="sd">            pred   : predicted labels from the neural network</span>
<span class="sd">            target : true &quot;label&quot; labels</span>
<span class="sd">        Returns:</span>
<span class="sd">            loss   : cross-entropy loss</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">yhat</span> <span class="o">=</span> <span class="n">pred</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">target</span>
        <span class="n">m</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># commpute loss</span>
        <span class="n">term1</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">yhat</span><span class="p">)))</span>
        <span class="n">term2</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">),(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">yhat</span><span class="p">))))</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="n">m</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">term1</span><span class="o">+</span><span class="n">term2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">loss</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">)</span> <span class="c1"># convert array to a single value number</span>
    
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the gradinets of the loss_fn wrt to the predicted labels</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">         da : derivative of loss_fn wrt to the predicted labels</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># derivative of loss_fn with respect to a [predicted labels]</span>
        <span class="n">da</span> <span class="o">=</span> <span class="o">-</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">yhat</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">yhat</span><span class="p">))</span> 
        <span class="k">return</span> <span class="n">da</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Model:">Model:<a class="anchor-link" href="#Model:"> </a></h2><p><strong>Let's go over the architecture that we are going to use for our neural netwok:</strong></p>
<ul>
<li>Our model is going to have 2 hidden layers and a output layer. </li>
<li>The 2 <code>hidden layers</code> <code>(linear layers)</code> are going to have <code>16 units</code> each followed by a <code>ReLU</code> activation layer and the <code>output layer</code> <code>(linear layer)</code> is going to have <code>1 unit</code> followed by a <code>Sigmoid</code> unit. </li>
<li>The output layer is going to predict the <code>probability</code> of wether the given input is either a <code>0</code> or a <code>1</code>. If the predicted probability is <code>&gt; 0.5 we</code> will assumse that the <code>predicted output</code> is <code>1</code> else <code>0</code>.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's assemble the layers required to construct out model:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>These are our inputs and targets:</strong></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p><div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of Inputs:&quot;</span><span class="p">,</span> <span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of Targets:&quot;</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_train</span><span class="p">))</span>
    <span class="n">val</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">val</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;binary&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Target value: </span><span class="si">{</span><span class="n">y_train</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>
</p>
    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Shape of Inputs: (10610, 784)
Shape of Targets: (10610, 1)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Initialize model parameters:</strong></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nh1</span> <span class="o">=</span> <span class="mi">16</span> <span class="c1"># no. of units in the first hidden layer</span>
<span class="n">nh2</span> <span class="o">=</span> <span class="mi">16</span> <span class="c1"># no. of units in the 2nd hidden layer</span>
<span class="n">nh3</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># no. of units in the output layer</span>

<span class="n">w1</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">nh1</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span>
<span class="n">b1</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">nh1</span><span class="p">))</span>

<span class="n">w2</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">nh1</span><span class="p">,</span> <span class="n">nh2</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span>
<span class="n">b2</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">nh2</span><span class="p">))</span>

<span class="n">w3</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">nh2</span><span class="p">,</span> <span class="n">nh3</span><span class="p">)</span>
<span class="n">b3</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">nh3</span><span class="p">))</span>

<span class="n">w1</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">b1</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">w2</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">b2</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">w3</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">b3</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Instaniating the layers needed to construct our model:</strong></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lin1</span>    <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">w1</span><span class="p">,</span><span class="n">b1</span><span class="p">)</span> <span class="c1"># 1 hidden layer</span>
<span class="n">relu1</span>   <span class="o">=</span> <span class="n">RelU</span><span class="p">()</span>
<span class="n">lin2</span>    <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">w2</span><span class="p">,</span><span class="n">b2</span><span class="p">)</span> <span class="c1"># 2nd hidden layer</span>
<span class="n">relu2</span>   <span class="o">=</span> <span class="n">RelU</span><span class="p">()</span>
<span class="n">lin3</span>    <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">w3</span><span class="p">,</span><span class="n">b3</span><span class="p">)</span> <span class="c1"># output layer</span>
<span class="n">sigmoid</span> <span class="o">=</span> <span class="n">Sigmoid</span><span class="p">()</span>

<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">CELoss</span><span class="p">()</span> <span class="c1"># loss_fn</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Forward-pass:">Forward pass:<a class="anchor-link" href="#Forward-pass:"> </a></h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">z1</span>   <span class="o">=</span> <span class="n">lin1</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
<span class="n">a1</span>   <span class="o">=</span> <span class="n">relu1</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">z1</span><span class="p">)</span>
<span class="n">z2</span>   <span class="o">=</span> <span class="n">lin2</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">a1</span><span class="p">)</span>
<span class="n">a2</span>   <span class="o">=</span> <span class="n">relu2</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">z2</span><span class="p">)</span>
<span class="n">z3</span>   <span class="o">=</span> <span class="n">lin3</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">a2</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">a3</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">z3</span><span class="p">)</span>

<span class="c1"># calculate loss</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loss:&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span> <span class="c1"># print out the loss</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Loss: 0.6914281432245456
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Backward-pass:">Backward pass:<a class="anchor-link" href="#Backward-pass:"> </a></h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">da3</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span> <span class="c1"># gradient of loss wrt to final output</span>
<span class="n">dz3</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">da3</span><span class="p">)</span>

<span class="n">da2</span><span class="p">,</span> <span class="n">dw3</span><span class="p">,</span> <span class="n">db3</span> <span class="o">=</span> <span class="n">lin3</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">dz3</span><span class="p">)</span>

<span class="n">dz2</span> <span class="o">=</span> <span class="n">relu2</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">da2</span><span class="p">)</span>
<span class="n">da1</span><span class="p">,</span> <span class="n">dw2</span><span class="p">,</span> <span class="n">db2</span> <span class="o">=</span> <span class="n">lin2</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">dz2</span><span class="p">)</span>

<span class="n">dz1</span> <span class="o">=</span> <span class="n">relu1</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">da1</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">dw1</span><span class="p">,</span> <span class="n">db1</span> <span class="o">=</span> <span class="n">lin1</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">da1</span><span class="p">)</span>

<span class="c1"># check if the parameters and the gradients are of same shape</span>
<span class="c1"># so that we can preform the update state</span>
<span class="k">assert</span> <span class="n">lin1</span><span class="o">.</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">dw1</span><span class="o">.</span><span class="n">shape</span>
<span class="k">assert</span> <span class="n">lin2</span><span class="o">.</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">dw2</span><span class="o">.</span><span class="n">shape</span>
<span class="k">assert</span> <span class="n">lin3</span><span class="o">.</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">dw3</span><span class="o">.</span><span class="n">shape</span>

<span class="k">assert</span> <span class="n">lin1</span><span class="o">.</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">db1</span><span class="o">.</span><span class="n">shape</span>
<span class="k">assert</span> <span class="n">lin2</span><span class="o">.</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">db2</span><span class="o">.</span><span class="n">shape</span>
<span class="k">assert</span> <span class="n">lin3</span><span class="o">.</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">db3</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Update-parameters:">Update parameters:<a class="anchor-link" href="#Update-parameters:"> </a></h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.0002</span>

<span class="c1"># update parameters </span>
<span class="n">lin1</span><span class="o">.</span><span class="n">w</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dw1</span>
<span class="n">lin2</span><span class="o">.</span><span class="n">w</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dw2</span>
<span class="n">lin3</span><span class="o">.</span><span class="n">w</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dw3</span>

<span class="n">lin1</span><span class="o">.</span><span class="n">b</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">db1</span>
<span class="n">lin2</span><span class="o">.</span><span class="n">b</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">db2</span>
<span class="n">lin3</span><span class="o">.</span><span class="n">b</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">db3</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So, this is how our training our model is going to look we first calculate the <code>loss</code> of the model during the <code>forward pass</code> , then we calculate the gradients of the <code>loss</code> wrt to the <code>parameters</code> of the model. After which these <code>gradients</code> are used to <code>update the model parameters</code>. We continue this workflow for a certain number of <code>iterations</code> or until our <code>loss</code> reaches the desired value.</p>
<p>Let's code up a class which will make this steps easir to achieve.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Putting-it-all-together:">Putting it all together:<a class="anchor-link" href="#Putting-it-all-together:"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><strong>Initializing parameters:</strong></li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Instantiate parameters</span>
<span class="n">nh1</span> <span class="o">=</span> <span class="mi">16</span> <span class="c1"># no. of units in the first hidden layer</span>
<span class="n">nh2</span> <span class="o">=</span> <span class="mi">16</span> <span class="c1"># no. of units in the 2nd hidden layer</span>
<span class="n">nh3</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># no. of units in the output layer</span>

<span class="n">w1</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">nh1</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span>
<span class="n">b1</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">nh1</span><span class="p">))</span>

<span class="n">w2</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">nh1</span><span class="p">,</span> <span class="n">nh2</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span>
<span class="n">b2</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">nh2</span><span class="p">))</span>

<span class="n">w3</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">nh2</span><span class="p">,</span> <span class="n">nh3</span><span class="p">)</span>
<span class="n">b3</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">nh3</span><span class="p">))</span>

<span class="n">w1</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">b1</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">w2</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">b2</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">w3</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">b3</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For our convenice, we will create a <code>Model</code> class .</p>
<p>This <code>Model</code> class will store all the parameters for our neural-network.
The <code>forward</code> method will compute the <code>forward pass</code> of the network to generate the <code>loss</code> (and or <code>predictions</code>) of the model. The <code>backward</code> method will compute the <code>backward pass</code> of the network to get the gradinets of the <code>loss</code> wrt to the <code>parameters</code> of the model. Finally the <code>update</code> method will update the parameters of the model.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Model</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A simple neural network model</span>
<span class="sd">        The `forward` method computes the forward propagation step of the model</span>
<span class="sd">        The `backward` method computes the backward step propagation of the model</span>
<span class="sd">        The `update_step` method updates the parameters of the model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin1</span>    <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">w1</span><span class="p">,</span><span class="n">b1</span><span class="p">)</span> <span class="c1"># 1st linear layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu1</span>   <span class="o">=</span> <span class="n">RelU</span><span class="p">()</span>        <span class="c1"># 1st activation layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin2</span>    <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">w2</span><span class="p">,</span><span class="n">b2</span><span class="p">)</span> <span class="c1"># 2nd linear layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu2</span>   <span class="o">=</span> <span class="n">RelU</span><span class="p">()</span>        <span class="c1"># 2nd activation layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin3</span>    <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">w3</span><span class="p">,</span><span class="n">b3</span><span class="p">)</span> <span class="c1"># 3rd linear layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">Sigmoid</span><span class="p">()</span>     <span class="c1"># 3rd activation layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">CELoss</span><span class="p">()</span>      <span class="c1"># loss_fn</span>
        
        <span class="c1"># learning_rate to update model parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr</span>      <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="c1"># stores the loss at each iteration</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">losses</span>  <span class="o">=</span> <span class="p">[]</span> 


    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">calc_loss</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">targ</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computs the forward step for out model Additionally</span>
<span class="sd">        it also returns the loss [Optional] and the predictions</span>
<span class="sd">        of the model.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            inp       : the training set.</span>
<span class="sd">            calc_loss : wether to calculate loss of the model if False only predictions</span>
<span class="sd">                        are calculated.</span>
<span class="sd">            targ      : the original targets to the training set. </span>
<span class="sd">        </span>
<span class="sd">        Note: to calculate the `loss` the `targ` must be given</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            pred : outputs of the 3rd activation layer.</span>
<span class="sd">            loss : [Optional] loss the model , if the `targ` is given.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">out</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu1</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lin1</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">inp</span><span class="p">))</span>
        <span class="n">out</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu2</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lin2</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">out</span><span class="p">))</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lin3</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">out</span><span class="p">))</span>
        
        <span class="k">if</span> <span class="n">calc_loss</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">targ</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;to calculate loss targets must be given&quot;</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">targ</span><span class="p">)</span>
            <span class="c1"># appending the loss of the current iteration</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">pred</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">pred</span>
        
    <span class="k">def</span> <span class="nf">_assert_shapes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Checks the shape of the parameters and the gradients of the model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">lin1</span><span class="o">.</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">dw1</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">assert</span> <span class="n">lin2</span><span class="o">.</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">dw2</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">assert</span> <span class="n">lin3</span><span class="o">.</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">dw3</span><span class="o">.</span><span class="n">shape</span>

        <span class="k">assert</span> <span class="n">lin1</span><span class="o">.</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">db1</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">assert</span> <span class="n">lin2</span><span class="o">.</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">db2</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">assert</span> <span class="n">lin3</span><span class="o">.</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">db3</span><span class="o">.</span><span class="n">shape</span>


    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the backward step</span>
<span class="sd">        and return the gradients of the parameters with the loss</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">da3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">dz3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">da3</span><span class="p">)</span>
        <span class="n">da2</span><span class="p">,</span> <span class="n">dw3</span><span class="p">,</span> <span class="n">db3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lin3</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">dz3</span><span class="p">)</span>
        
        <span class="n">dz2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu2</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">da2</span><span class="p">)</span>
        <span class="n">da1</span><span class="p">,</span> <span class="n">dw2</span><span class="p">,</span> <span class="n">db2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lin2</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">dz2</span><span class="p">)</span>

        <span class="n">dz1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu1</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">da1</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">dw1</span><span class="p">,</span> <span class="n">db1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lin1</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">dz1</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">_assert_shapes</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dws</span> <span class="o">=</span> <span class="p">[</span><span class="n">dw1</span><span class="p">,</span> <span class="n">dw2</span><span class="p">,</span> <span class="n">dw3</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">db1</span><span class="p">,</span> <span class="n">db2</span><span class="p">,</span> <span class="n">db3</span><span class="p">]</span>


    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Performs the update step</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin1</span><span class="o">.</span><span class="n">w</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">dws</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin2</span><span class="o">.</span><span class="n">w</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">dws</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin3</span><span class="o">.</span><span class="n">w</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">dws</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">lin1</span><span class="o">.</span><span class="n">b</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">dbs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin2</span><span class="o">.</span><span class="n">b</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">dbs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin3</span><span class="o">.</span><span class="n">b</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">dbs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nn</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.0005</span><span class="p">)</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">60</span> <span class="c1"># no. of iterations to train</span>

<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">loss</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">calc_loss</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">targ</span><span class="o">=</span><span class="n">y_train</span><span class="p">)</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loss after interation </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2"> is </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Loss after interation 0 is 0.6924
Loss after interation 1 is 0.6900
Loss after interation 2 is 0.6859
Loss after interation 3 is 0.6826
Loss after interation 4 is 0.6760
Loss after interation 5 is 0.6683
Loss after interation 6 is 0.6565
Loss after interation 7 is 0.6415
Loss after interation 8 is 0.6190
Loss after interation 9 is 0.5894
Loss after interation 10 is 0.5532
Loss after interation 11 is 0.5110
Loss after interation 12 is 0.4643
Loss after interation 13 is 0.4128
Loss after interation 14 is 0.3635
Loss after interation 15 is 0.3164
Loss after interation 16 is 0.2747
Loss after interation 17 is 0.2389
Loss after interation 18 is 0.2086
Loss after interation 19 is 0.1834
Loss after interation 20 is 0.1624
Loss after interation 21 is 0.1448
Loss after interation 22 is 0.1300
Loss after interation 23 is 0.1174
Loss after interation 24 is 0.1068
Loss after interation 25 is 0.0976
Loss after interation 26 is 0.0897
Loss after interation 27 is 0.0828
Loss after interation 28 is 0.0769
Loss after interation 29 is 0.0716
Loss after interation 30 is 0.0670
Loss after interation 31 is 0.0628
Loss after interation 32 is 0.0591
Loss after interation 33 is 0.0559
Loss after interation 34 is 0.0529
Loss after interation 35 is 0.0502
Loss after interation 36 is 0.0478
Loss after interation 37 is 0.0456
Loss after interation 38 is 0.0436
Loss after interation 39 is 0.0417
Loss after interation 40 is 0.0400
Loss after interation 41 is 0.0384
Loss after interation 42 is 0.0370
Loss after interation 43 is 0.0357
Loss after interation 44 is 0.0344
Loss after interation 45 is 0.0333
Loss after interation 46 is 0.0322
Loss after interation 47 is 0.0312
Loss after interation 48 is 0.0302
Loss after interation 49 is 0.0294
Loss after interation 50 is 0.0285
Loss after interation 51 is 0.0278
Loss after interation 52 is 0.0270
Loss after interation 53 is 0.0263
Loss after interation 54 is 0.0257
Loss after interation 55 is 0.0251
Loss after interation 56 is 0.0245
Loss after interation 57 is 0.0239
Loss after interation 58 is 0.0234
Loss after interation 59 is 0.0229
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p><div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">losses</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;teal&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Loss per Iteration&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Iteration&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>
</p>
    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Computing-accuracy-of-our-model">Computing accuracy of our model<a class="anchor-link" href="#Computing-accuracy-of-our-model"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Let's check our model performance by computing the <code>accuracy</code> on the <code>validation</code> dataset</strong></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">comp_accuracy</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">targs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fn that computes the accuracy between the predicted values and the targets</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">targs</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
    <span class="c1"># convert probas to 0/1 predictions</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">preds</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">preds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
            <span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy: &quot;</span>  <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">p</span> <span class="o">==</span> <span class="n">targs</span><span class="p">)</span><span class="o">/</span><span class="n">m</span><span class="p">)))</span>    
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>computing accuracy on the train set:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">preds</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">calc_loss</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="c1"># generate predictions from our model</span>
<span class="c1"># compute accuracy</span>
<span class="n">comp_accuracy</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Accuracy: 0.9971724787935912
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>computing accuracy on the validation set:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">preds</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x_valid</span><span class="p">,</span> <span class="n">calc_loss</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="c1"># generate predictions from our model</span>
<span class="c1"># compute accuracy</span>
<span class="n">comp_accuracy</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Accuracy: 0.9980535279805351
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>our model achieved a <code>accuracy</code> of <strong><code>0.99</code></strong> on both the <code>train</code> and the <code>validation</code> set !
</div></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Generating-predictions-from-the-model">Generating predictions from the model<a class="anchor-link" href="#Generating-predictions-from-the-model"> </a></h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p><div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_inp</span> <span class="o">=</span> <span class="n">x_valid</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># one example from the validation set</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Input: &quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">test_inp</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;binary&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">pred</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">test_inp</span><span class="p">,</span> <span class="n">calc_loss</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">predicted_val</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">pred</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Predicted output: </span><span class="si">{</span><span class="n">predicted_val</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>
</p>
    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Predicted output: 0
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p><div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_inp</span> <span class="o">=</span> <span class="n">x_valid</span><span class="p">[</span><span class="mi">2000</span><span class="p">]</span> <span class="c1"># one example from the validation set</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Input: &quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">test_inp</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;binary&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">pred</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">test_inp</span><span class="p">,</span> <span class="n">calc_loss</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">predicted_val</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">pred</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Predicted output: </span><span class="si">{</span><span class="n">predicted_val</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>
</p>
    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Predicted output: 1
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Summary:">Summary:<a class="anchor-link" href="#Summary:"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>We were able to create a model that can identify classify handwritten digits as either 1's or 0's</li>
<li>We successfully computed the <code>forward</code> and <code>backward</code> progation of a <code>neural network</code> from scratch.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Thanks for reading !</strong></p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="benihime91/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blog/machinelearning%20deeplearning%20python3.x%20numpy/2020/09/22/nn-from-scratch.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Tips, Tricks and Tutorials for Deep-Learning enthusiasts.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/benihime91" title="benihime91"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/Ayushma75139217" title="Ayushma75139217"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
