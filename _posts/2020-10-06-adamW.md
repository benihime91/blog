---
keywords: fastai
description: A post explaining L2 regularization, Weight decay and AdamW optimizer as described in the paper Decoupled Weight Decay Regularization we will also go over how to implement these using tensorflow2.x .
title: Understanding L2 regularization, Weight decay and AdamW
toc: false
badges: true
comments: true
categories: [machinelearning deeplearning python3.x tensorflow2.x]
nb_path: _notebooks/adamW.ipynb
layout: notebook
---

<!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/adamW.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="What-is-regularization-?">What is regularization ?<a class="anchor-link" href="#What-is-regularization-?"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In simple words regularization helps in reduces over-fitting on the data. There are many regularization strategies.</p>
<p>The major regularization techniques used in practice are:</p>
<ul>
<li>L2 Regularization</li>
<li>L1 Regularization</li>
<li>Data Augmentation</li>
<li>Dropout</li>
<li>Early Stopping</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="L2-regularization-:">L2 regularization :<a class="anchor-link" href="#L2-regularization-:"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In L2 regularization, an extra term often referred to as regularization term is added to the loss function of the network.</p>
<p>Consider the the following cross entropy loss function (without regularization):</p>
<p>{% raw %}
$$loss= -\frac{1}{m} \sum\limits_{i = 1}^{m} (y^{(i)}\log\left(yhat^{(i)}\right) + (1-y^{(i)})\log\left(1-yhat^{(i)}\right)) $$
{% endraw %}</p>
<p>To apply L2 regularization to the loss function above we add the term given below to the loss function :</p>
<p>{% raw %}
$$\frac{\lambda}{2m}\sum\limits_{w}w^{2} $$
{% endraw %}</p>
<p>where $\lambda$ is a hyperparameter of the model known as the regularization parameter. $\lambda$ is a hyper-parameter which means it is not learned during the training but is tuned by the user manually</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>After applying the <code>regularization term</code> to our original loss function :
{% raw %}
$$finalLoss= -\frac{1}{m} \sum\limits_{i = 1}^{m} (y^{(i)}\log\left(yhat^{(i)}\right) + (1-y^{(i)})\log\left(1-yhat^{(i)}\right)) + \frac{\lambda}{2m}\sum\limits_{w}w^{2}$$
{% endraw %}</p>
<p>or , 
{% raw %}
$$ finalLoss = loss+ \frac{\lambda}{2m}\sum\limits_{w}w^{2}$$
{% endraw %}</p>
<p>or in simple code :</p>
<div class="highlight"><pre><span></span><span class="n">final_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)</span> <span class="o">+</span> <span class="n">lamdba</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="mi">2</span>
<span class="n">final_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)</span> <span class="o">+</span> <span class="n">lamdba</span> <span class="o">*</span> <span class="n">l2_reg_term</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='all code equations are written in python, numpy notation.' %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Cosequently the weight update step for <strong>vanilla SGD</strong> is going to look something like this:</p>
<div class="highlight"><pre><span></span><span class="n">w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grad_w</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">lamdba</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">l2_reg_term</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grad_w</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">lamdba</span> <span class="o">*</span> <span class="n">w</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='assume that grad_w is the gradients of the loss of the model wrt weights of the model' %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='assume that grad(a,b) calculates the gradients of a wrt to b' %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Weight-Decay-:">Weight Decay :<a class="anchor-link" href="#Weight-Decay-:"> </a></h2>
</div>
</div>
</div>
</div>
 

