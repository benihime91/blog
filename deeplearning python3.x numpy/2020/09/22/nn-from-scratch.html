<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Creating a NeuralNetwork from scratch | Another Deep-Learning Blog</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Creating a NeuralNetwork from scratch" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A tutorial to code a neural network from scratch in python using numpy." />
<meta property="og:description" content="A tutorial to code a neural network from scratch in python using numpy." />
<link rel="canonical" href="https://benihime91.github.io/blog/deeplearning%20python3.x%20numpy/2020/09/22/nn-from-scratch.html" />
<meta property="og:url" content="https://benihime91.github.io/blog/deeplearning%20python3.x%20numpy/2020/09/22/nn-from-scratch.html" />
<meta property="og:site_name" content="Another Deep-Learning Blog" />
<meta property="og:image" content="https://benihime91.github.io/blog/images/backprop.jpeg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-09-22T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"A tutorial to code a neural network from scratch in python using numpy.","url":"https://benihime91.github.io/blog/deeplearning%20python3.x%20numpy/2020/09/22/nn-from-scratch.html","@type":"BlogPosting","headline":"Creating a NeuralNetwork from scratch","dateModified":"2020-09-22T00:00:00-05:00","datePublished":"2020-09-22T00:00:00-05:00","image":"https://benihime91.github.io/blog/images/backprop.jpeg","mainEntityOfPage":{"@type":"WebPage","@id":"https://benihime91.github.io/blog/deeplearning%20python3.x%20numpy/2020/09/22/nn-from-scratch.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://benihime91.github.io/blog/feed.xml" title="Another Deep-Learning Blog" /><link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Another Deep-Learning Blog</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Creating a NeuralNetwork from scratch</h1><p class="page-description">A tutorial to code a neural network from scratch in python using numpy.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-09-22T00:00:00-05:00" itemprop="datePublished">
        Sep 22, 2020
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      16 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#deeplearning python3.x numpy">deeplearning python3.x numpy</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/benihime91/blog/tree/master/_notebooks/2020-09-22-nn-from-scratch.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/benihime91/blog/master?filepath=_notebooks%2F2020-09-22-nn-from-scratch.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/benihime91/blog/blob/master/_notebooks/2020-09-22-nn-from-scratch.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-09-22-nn-from-scratch.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I will assume that you all know what a artificial neural network is and have a little bit of knowledge about <code>forward and backward propagation</code>. Just having a simple idea is enough.
<div class="flash flash-success">
    <svg class="octicon octicon-checklist octicon octicon-checklist" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M2.5 1.75a.25.25 0 01.25-.25h8.5a.25.25 0 01.25.25v7.736a.75.75 0 101.5 0V1.75A1.75 1.75 0 0011.25 0h-8.5A1.75 1.75 0 001 1.75v11.5c0 .966.784 1.75 1.75 1.75h3.17a.75.75 0 000-1.5H2.75a.25.25 0 01-.25-.25V1.75zM4.75 4a.75.75 0 000 1.5h4.5a.75.75 0 000-1.5h-4.5zM4 7.75A.75.75 0 014.75 7h2a.75.75 0 010 1.5h-2A.75.75 0 014 7.75zm11.774 3.537a.75.75 0 00-1.048-1.074L10.7 14.145 9.281 12.72a.75.75 0 00-1.062 1.058l1.943 1.95a.75.75 0 001.055.008l4.557-4.45z"></path></svg>
    <strong>Tip: </strong>If you do not know what the above terms are or would like to brush up on the topics, I would suggest going through this amazing <a href="https://www.youtube.com/watch?v=aircAruvnKk&amp;list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi">youtube playlist</a> by <a href="https://www.3blue1brown.com/">3Blue1Brown</a>.
</div></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>
<center>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/watch?v=aircAruvnKk&amp;list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi" frameborder="0" allowfullscreen=""></iframe>
</center>
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Setting-up-Imports:">Setting up Imports:<a class="anchor-link" href="#Setting-up-Imports:"> </a></h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">gzip</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">warnings</span>


<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Preparing-the-data">Preparing the data<a class="anchor-link" href="#Preparing-the-data"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For this blog post, we'll use one of the most famous datasets in computer vision, <a href="https://en.wikipedia.org/wiki/MNIST_database">MNIST</a>. MNIST contains images of handwritten digits, collected by the National Institute of Standards and Technology and collated into a machine learning dataset by Yann Lecun and his colleagues. Lecun used MNIST in 1998 in <a href="http://yann.lecun.com/exdb/lenet/">Lenet-5</a>, the first computer system to demonstrate practically useful recognition of handwritten digit sequences. This was one of the most important breakthroughs in the history of AI.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Run the code given below to download the <code>MNIST</code> dataset.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="highlight"><pre><span></span>wget -P path http://deeplearning.net/data/mnist/mnist.pkl.gz
</pre></div>
<p><div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>the above code snippet will download the dataset to <code>{path}</code> so be sure to set the <code>{path}</code> to the desired location of your choice. 
</div></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_data</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fn to unzip the MNIST data and return</span>
<span class="sd">    the data as numpy arrays</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">gzip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="p">((</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">),</span> <span class="n">_</span><span class="p">)</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;latin-1&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">map</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">,</span> <span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">x_valid</span><span class="p">,</span><span class="n">y_valid</span><span class="p">))</span>


<span class="c1"># Grab the MNIST dataset</span>
<span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">x_valid</span><span class="p">,</span><span class="n">y_valid</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="n">path</span><span class="o">=</span> <span class="s2">&quot;../../Datasets/mnist.pkl.gz&quot;</span><span class="p">)</span>

<span class="n">tots</span><span class="p">,</span><span class="n">feats</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">shape</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of x_train:&quot;</span><span class="p">,</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total number of examples:&quot;</span><span class="p">,</span> <span class="n">tots</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of pixel values per image:&quot;</span><span class="p">,</span> <span class="n">feats</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Shape of x_train: (50000, 784)
Total number of examples: 50000
Number of pixel values per image: 784
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Preparing-our-train-&amp;-validation-datasets">Preparing our <code>train</code> &amp; <code>validation</code> datasets<a class="anchor-link" href="#Preparing-our-train-&amp;-validation-datasets"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To make our life a bit easier we are going to take only the examples that contain a 1 or 0.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">zero_mask</span> <span class="o">=</span> <span class="p">[</span><span class="n">y_train</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># grab all the index values where 0 is present</span>
<span class="n">one_mask</span> <span class="o">=</span> <span class="p">[</span><span class="n">y_train</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># grad all the index valus where 1 is present</span>

<span class="c1"># grab all the 1&#39;s and 0&#39;s and make training set</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">x_train</span><span class="p">[</span><span class="n">zero_mask</span><span class="p">],</span> <span class="n">x_train</span><span class="p">[</span><span class="n">one_mask</span><span class="p">]))</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">y_train</span><span class="p">[</span><span class="n">zero_mask</span><span class="p">],</span> <span class="n">y_train</span><span class="p">[</span><span class="n">one_mask</span><span class="p">])))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>

<span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>((10610, 784), (10610, 1))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Our training set now has 10610 examples</strong></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">zero_mask</span> <span class="o">=</span> <span class="p">[</span><span class="n">y_valid</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># grab all the index values where 0 is present</span>
<span class="n">one_mask</span> <span class="o">=</span> <span class="p">[</span><span class="n">y_valid</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># grad all the index valus where 1 is present</span>

<span class="c1"># grab all the 1&#39;s and 0&#39;s and make training set</span>
<span class="n">x_valid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">x_valid</span><span class="p">[</span><span class="n">zero_mask</span><span class="p">],</span> <span class="n">x_valid</span><span class="p">[</span><span class="n">one_mask</span><span class="p">]))</span>
<span class="n">y_valid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">y_valid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">y_valid</span><span class="p">[</span><span class="n">zero_mask</span><span class="p">],</span> <span class="n">y_valid</span><span class="p">[</span><span class="n">one_mask</span><span class="p">])))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>

<span class="n">x_valid</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_valid</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>((2055, 784), (2055, 1))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Our validation set now has 2055 examples</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Why do we need different training and validation sets ?</strong></p>
<p>Since, this topic requires a different post on it's own I won't be covering it here. But you can get the idea from this above video:

<center>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/1waHlpKiNyY?t=243" frameborder="0" allowfullscreen=""></iframe>
</center>
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's view some example images from our dataset:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p><div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">x_train</span><span class="p">[</span><span class="mi">50</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;binary&quot;</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>
</p>
    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p><div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">x_train</span><span class="p">[</span><span class="mi">5000</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;binary&quot;</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>
</p>
    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Basic-Model-Architecture">Basic Model Architecture<a class="anchor-link" href="#Basic-Model-Architecture"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For this task we are going to use a very basic model architecture this 2 linear layers and a output layer with 1 unit.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_svg output_subarea output_execute_result">
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
&lt;!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"&gt;
<!-- Generated by graphviz version 2.44.0 (20200408.0750)
 -->
<!-- Title: G Pages: 1 -->
<svg width="811pt" height="260pt" viewBox="0.00 0.00 810.56 260.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 256)">
<title>G</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-256 806.56,-256 806.56,4 -4,4" />
<!-- X -->
<g id="node1" class="node">
<title>X</title>
<ellipse fill="none" stroke="black" cx="27" cy="-234" rx="27" ry="18" />
<text text-anchor="middle" x="27" y="-230.3" font-family="Times,serif" font-size="14.00">X</text>
</g>
<!-- linear1 -->
<g id="node2" class="node">
<title>linear1</title>
<ellipse fill="none" stroke="black" cx="125.1" cy="-180" rx="35.19" ry="18" />
<text text-anchor="middle" x="125.1" y="-176.3" font-family="Times,serif" font-size="14.00">linear1</text>
</g>
<!-- X&#45;&gt;linear1 -->
<g id="edge1" class="edge">
<title>X&#45;&gt;linear1</title>
<path fill="none" stroke="black" d="M48.38,-222.55C60.94,-215.49 77.34,-206.28 91.66,-198.23" />
<polygon fill="black" stroke="black" points="93.7,-201.1 100.7,-193.15 90.27,-194.99 93.7,-201.1" />
</g>
<!-- relu1 -->
<g id="node3" class="node">
<title>relu1</title>
<ellipse fill="none" stroke="black" cx="224.79" cy="-180" rx="28.7" ry="18" />
<text text-anchor="middle" x="224.79" y="-176.3" font-family="Times,serif" font-size="14.00">relu1</text>
</g>
<!-- linear1&#45;&gt;relu1 -->
<g id="edge2" class="edge">
<title>linear1&#45;&gt;relu1</title>
<path fill="none" stroke="black" d="M160.27,-180C168.56,-180 177.47,-180 185.93,-180" />
<polygon fill="black" stroke="black" points="185.93,-183.5 195.93,-180 185.93,-176.5 185.93,-183.5" />
</g>
<!-- linear2 -->
<g id="node4" class="node">
<title>linear2</title>
<ellipse fill="none" stroke="black" cx="324.49" cy="-126" rx="35.19" ry="18" />
<text text-anchor="middle" x="324.49" y="-122.3" font-family="Times,serif" font-size="14.00">linear2</text>
</g>
<!-- relu1&#45;&gt;linear2 -->
<g id="edge3" class="edge">
<title>relu1&#45;&gt;linear2</title>
<path fill="none" stroke="black" d="M246.99,-168.28C259.79,-161.21 276.36,-152.05 290.81,-144.06" />
<polygon fill="black" stroke="black" points="292.87,-146.92 299.93,-139.02 289.49,-140.79 292.87,-146.92" />
</g>
<!-- relu2 -->
<g id="node5" class="node">
<title>relu2</title>
<ellipse fill="none" stroke="black" cx="424.18" cy="-126" rx="28.7" ry="18" />
<text text-anchor="middle" x="424.18" y="-122.3" font-family="Times,serif" font-size="14.00">relu2</text>
</g>
<!-- linear2&#45;&gt;relu2 -->
<g id="edge4" class="edge">
<title>linear2&#45;&gt;relu2</title>
<path fill="none" stroke="black" d="M359.65,-126C367.95,-126 376.86,-126 385.32,-126" />
<polygon fill="black" stroke="black" points="385.32,-129.5 395.32,-126 385.32,-122.5 385.32,-129.5" />
</g>
<!-- linear3 -->
<g id="node6" class="node">
<title>linear3</title>
<ellipse fill="none" stroke="black" cx="523.87" cy="-72" rx="35.19" ry="18" />
<text text-anchor="middle" x="523.87" y="-68.3" font-family="Times,serif" font-size="14.00">linear3</text>
</g>
<!-- relu2&#45;&gt;linear3 -->
<g id="edge5" class="edge">
<title>relu2&#45;&gt;linear3</title>
<path fill="none" stroke="black" d="M446.38,-114.28C459.18,-107.21 475.75,-98.05 490.2,-90.06" />
<polygon fill="black" stroke="black" points="492.26,-92.92 499.32,-85.02 488.88,-86.79 492.26,-92.92" />
</g>
<!-- sigmoid -->
<g id="node7" class="node">
<title>sigmoid</title>
<ellipse fill="none" stroke="black" cx="634.62" cy="-72" rx="39.79" ry="18" />
<text text-anchor="middle" x="634.62" y="-68.3" font-family="Times,serif" font-size="14.00">sigmoid</text>
</g>
<!-- linear3&#45;&gt;sigmoid -->
<g id="edge6" class="edge">
<title>linear3&#45;&gt;sigmoid</title>
<path fill="none" stroke="black" d="M558.98,-72C567.13,-72 575.99,-72 584.66,-72" />
<polygon fill="black" stroke="black" points="584.7,-75.5 594.7,-72 584.7,-68.5 584.7,-75.5" />
</g>
<!-- prediction -->
<g id="node8" class="node">
<title>prediction</title>
<ellipse fill="none" stroke="black" cx="756.41" cy="-72" rx="46.29" ry="18" />
<text text-anchor="middle" x="756.41" y="-68.3" font-family="Times,serif" font-size="14.00">prediction</text>
</g>
<!-- sigmoid&#45;&gt;prediction -->
<g id="edge7" class="edge">
<title>sigmoid&#45;&gt;prediction</title>
<path fill="none" stroke="black" d="M674.51,-72C682.66,-72 691.41,-72 700.03,-72" />
<polygon fill="black" stroke="black" points="700.05,-75.5 710.05,-72 700.05,-68.5 700.05,-75.5" />
</g>
<!-- W1 -->
<g id="node9" class="node">
<title>W1</title>
<ellipse fill="none" stroke="black" cx="27" cy="-180" rx="27" ry="18" />
<text text-anchor="middle" x="27" y="-176.3" font-family="Times,serif" font-size="14.00">W1</text>
</g>
<!-- W1&#45;&gt;linear1 -->
<g id="edge8" class="edge">
<title>W1&#45;&gt;linear1</title>
<path fill="none" stroke="black" d="M54.01,-180C61.92,-180 70.84,-180 79.61,-180" />
<polygon fill="black" stroke="black" points="79.76,-183.5 89.76,-180 79.76,-176.5 79.76,-183.5" />
</g>
<!-- B1 -->
<g id="node10" class="node">
<title>B1</title>
<ellipse fill="none" stroke="black" cx="27" cy="-126" rx="27" ry="18" />
<text text-anchor="middle" x="27" y="-122.3" font-family="Times,serif" font-size="14.00">B1</text>
</g>
<!-- B1&#45;&gt;linear1 -->
<g id="edge9" class="edge">
<title>B1&#45;&gt;linear1</title>
<path fill="none" stroke="black" d="M48.38,-137.45C60.94,-144.51 77.34,-153.72 91.66,-161.77" />
<polygon fill="black" stroke="black" points="90.27,-165.01 100.7,-166.85 93.7,-158.9 90.27,-165.01" />
</g>
<!-- W2 -->
<g id="node11" class="node">
<title>W2</title>
<ellipse fill="none" stroke="black" cx="224.79" cy="-126" rx="27" ry="18" />
<text text-anchor="middle" x="224.79" y="-122.3" font-family="Times,serif" font-size="14.00">W2</text>
</g>
<!-- W2&#45;&gt;linear2 -->
<g id="edge10" class="edge">
<title>W2&#45;&gt;linear2</title>
<path fill="none" stroke="black" d="M251.97,-126C260.27,-126 269.68,-126 278.89,-126" />
<polygon fill="black" stroke="black" points="279.14,-129.5 289.14,-126 279.14,-122.5 279.14,-129.5" />
</g>
<!-- B2 -->
<g id="node12" class="node">
<title>B2</title>
<ellipse fill="none" stroke="black" cx="224.79" cy="-72" rx="27" ry="18" />
<text text-anchor="middle" x="224.79" y="-68.3" font-family="Times,serif" font-size="14.00">B2</text>
</g>
<!-- B2&#45;&gt;linear2 -->
<g id="edge11" class="edge">
<title>B2&#45;&gt;linear2</title>
<path fill="none" stroke="black" d="M246.03,-83.19C258.99,-90.35 276.1,-99.81 290.94,-108.01" />
<polygon fill="black" stroke="black" points="289.38,-111.15 299.83,-112.92 292.77,-105.02 289.38,-111.15" />
</g>
<!-- W3 -->
<g id="node13" class="node">
<title>W3</title>
<ellipse fill="none" stroke="black" cx="424.18" cy="-72" rx="27" ry="18" />
<text text-anchor="middle" x="424.18" y="-68.3" font-family="Times,serif" font-size="14.00">W3</text>
</g>
<!-- W3&#45;&gt;linear3 -->
<g id="edge12" class="edge">
<title>W3&#45;&gt;linear3</title>
<path fill="none" stroke="black" d="M451.36,-72C459.66,-72 469.07,-72 478.28,-72" />
<polygon fill="black" stroke="black" points="478.53,-75.5 488.53,-72 478.53,-68.5 478.53,-75.5" />
</g>
<!-- B3 -->
<g id="node14" class="node">
<title>B3</title>
<ellipse fill="none" stroke="black" cx="424.18" cy="-18" rx="27" ry="18" />
<text text-anchor="middle" x="424.18" y="-14.3" font-family="Times,serif" font-size="14.00">B3</text>
</g>
<!-- B3&#45;&gt;linear3 -->
<g id="edge13" class="edge">
<title>B3&#45;&gt;linear3</title>
<path fill="none" stroke="black" d="M445.42,-29.19C458.38,-36.35 475.49,-45.81 490.33,-54.01" />
<polygon fill="black" stroke="black" points="488.77,-57.15 499.22,-58.92 492.16,-51.02 488.77,-57.15" />
</g>
</g>
</svg>

</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>and then using the <code>predicted</code> value from the above model and the <code>real_target</code> value the loss is calculated:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_svg output_subarea output_execute_result">
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
&lt;!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"&gt;
<!-- Generated by graphviz version 2.44.0 (20200408.0750)
 -->
<!-- Title: G Pages: 1 -->
<svg width="190pt" height="98pt" viewBox="0.00 0.00 190.29 98.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 94)">
<title>G</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-94 186.29,-94 186.29,4 -4,4" />
<!-- prediction -->
<g id="node1" class="node">
<title>prediction</title>
<ellipse fill="none" stroke="black" cx="46.15" cy="-72" rx="46.29" ry="18" />
<text text-anchor="middle" x="46.15" y="-68.3" font-family="Times,serif" font-size="14.00">prediction</text>
</g>
<!-- loss -->
<g id="node2" class="node">
<title>loss</title>
<ellipse fill="none" stroke="black" cx="155.29" cy="-45" rx="27" ry="18" />
<text text-anchor="middle" x="155.29" y="-41.3" font-family="Times,serif" font-size="14.00">loss</text>
</g>
<!-- prediction&#45;&gt;loss -->
<g id="edge1" class="edge">
<title>prediction&#45;&gt;loss</title>
<path fill="none" stroke="black" d="M85.22,-62.4C96.55,-59.55 108.89,-56.44 119.97,-53.65" />
<polygon fill="black" stroke="black" points="120.88,-57.03 129.72,-51.19 119.16,-50.24 120.88,-57.03" />
</g>
<!-- target -->
<g id="node3" class="node">
<title>target</title>
<ellipse fill="none" stroke="black" cx="46.15" cy="-18" rx="30.59" ry="18" />
<text text-anchor="middle" x="46.15" y="-14.3" font-family="Times,serif" font-size="14.00">target</text>
</g>
<!-- target&#45;&gt;loss -->
<g id="edge2" class="edge">
<title>target&#45;&gt;loss</title>
<path fill="none" stroke="black" d="M74.46,-24.88C88.26,-28.36 105.16,-32.62 119.84,-36.32" />
<polygon fill="black" stroke="black" points="119.04,-39.73 129.59,-38.78 120.75,-32.94 119.04,-39.73" />
</g>
</g>
</svg>

</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Let's-take-a-deep-dive-into-what-this-network-means:">Let's take a deep dive into what this network means:<a class="anchor-link" href="#Let's-take-a-deep-dive-into-what-this-network-means:"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's take at look at all the individual components of this network:</p>
<ul>
<li><p><strong>Linear:</strong>
The linear layer computes the following :</p>

<pre><code> out = matmul(input,W1) + B1</code></pre>
</li>
<li><p><strong>ReLU:</strong> 
The relu computes the following:</p>

<pre><code>out = max(0, input)</code></pre>
</li>
<li><p><strong>Sigmoid:</strong> 
The sigmoid computes the following:</p>

<pre><code>out = 1/(1 + e.pow(input))</code></pre>
</li>
<li><p><strong>Loss:</strong> 
For the loss we are going to use the CrossEntropy Loss which is defined by the follwoing equation:
$$loss= -\frac{1}{m} \sum\limits_{i = 1}^{m} (y^{(i)}\log\left(yhat^{(i)}\right) + (1-y^{(i)})\log\left(1-yhat^{(i)}\right)) $$</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Now that we have our model architecture, let's create the different parts needed to assemble the model:</strong></p>
<ul>
<li>linear layer</li>
<li>relu activation</li>
<li>sigmoid activation</li>
<li>loss</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Let's first try to make some sense of what is happening in the backward and forward pass of our model:</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>On paper our forward pass would look something like this:</strong>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong><code>@</code> in python is the <code>matrix-multiplication operator</code>. 
</div></p>
<div class="highlight"><pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="n">x</span> <span class="c1"># original inputs</span>
<span class="n">targets</span> <span class="o">=</span> <span class="n">y</span> <span class="c1"># original targets</span>

<span class="n">z1</span> <span class="o">=</span> <span class="n">inputs</span> <span class="o">@</span> <span class="n">w2</span> <span class="o">+</span> <span class="n">b2</span>
<span class="n">a1</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">z1</span><span class="p">)</span>

<span class="n">z2</span> <span class="o">=</span> <span class="n">a1</span> <span class="o">@</span> <span class="n">w2</span> <span class="o">+</span> <span class="n">b2</span>
<span class="n">a2</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z2</span><span class="p">)</span> <span class="c1"># this is our model prediction</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">a2</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
</pre></div>
<p><div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>This is not actual code it&#8217;s just psuedo-code for understanding.
</div></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Consequently our backward pass would look something like this :</strong></p>
<p>(Let us assume that the <code>grad(inp, out)</code> computes the gradients of <code>inp</code> wrt <code>out</code>)</p>
<div class="highlight"><pre><span></span><span class="c1"># gradient of loss wrt output of the previous activation layer</span>
<span class="n">da2</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">a2</span><span class="p">)</span> 

<span class="c1"># gradient of loss wrt to z2</span>
<span class="n">dz2</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">z2</span><span class="p">)</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">a2</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">a2</span><span class="p">,</span><span class="n">z2</span><span class="p">)</span> 

<span class="c1"># gradient of the loss wrt to weight w2: [current layer]</span>
<span class="n">dw2</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">w2</span><span class="p">)</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">z2</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">z2</span><span class="p">,</span> <span class="n">w2</span><span class="p">)</span> <span class="o">=</span> <span class="n">dz2</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">z2</span><span class="p">,</span> <span class="n">w2</span><span class="p">)</span>
<span class="c1"># gradient of the loss wrt to bias b2: [current layer]</span>
<span class="n">db2</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">b2</span><span class="p">)</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">z2</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">z2</span><span class="p">,</span> <span class="n">b2</span><span class="p">)</span> <span class="o">=</span> <span class="n">dz2</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">z2</span><span class="p">,</span> <span class="n">b2</span><span class="p">)</span>
<span class="c1"># gradient of loss wrt a1: [previous layer]</span>
<span class="n">da1</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">a1</span><span class="p">)</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">z2</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">z2</span><span class="p">,</span> <span class="n">a1</span><span class="p">)</span> <span class="o">=</span> <span class="n">dz2</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">z2</span><span class="p">,</span> <span class="n">a1</span><span class="p">)</span>

<span class="c1"># gradient of loss wrt z1</span>
<span class="n">dz1</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">z1</span><span class="p">)</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">a1</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">a1</span><span class="p">,</span> <span class="n">z1</span><span class="p">)</span> <span class="o">=</span> <span class="n">da1</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">a1</span><span class="p">,</span> <span class="n">z1</span><span class="p">)</span>

<span class="c1"># gradient of the loss wrt to weight w1: [current layer]</span>
<span class="n">dw1</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">w1</span><span class="p">)</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">z1</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">z1</span><span class="p">,</span> <span class="n">w1</span><span class="p">)</span> <span class="o">=</span> <span class="n">dz1</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">z1</span><span class="p">,</span> <span class="n">w1</span><span class="p">)</span>
<span class="c1"># gradient of the loss wrt to bias b1: [current layer]</span>
<span class="n">db1</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">b1</span><span class="p">)</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">z1</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">z1</span><span class="p">,</span> <span class="n">b1</span><span class="p">)</span> <span class="o">=</span> <span class="n">dz1</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">z1</span><span class="p">,</span> <span class="n">b1</span><span class="p">)</span>
<span class="c1"># gradient of the loss wrt to a0: [previous layer]</span>
<span class="n">da0</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">a0</span><span class="p">)</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">z1</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">z1</span><span class="p">,</span> <span class="n">a0</span><span class="p">)</span> <span class="o">=</span> <span class="n">dz2</span> <span class="o">*</span> <span class="n">grad</span><span class="p">(</span><span class="n">z1</span><span class="p">,</span> <span class="n">a0</span><span class="p">)</span>


<span class="c1"># Update parameters :</span>
<span class="c1"># since we now have all the required gradients we can now perform the update step</span>
<span class="n">w1</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dw1</span>
<span class="n">b1</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">db1</span>

<span class="n">w2</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dw2</span>
<span class="n">b2</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">db2</span>
</pre></div>
<p><div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>This is not actual code it&#8217;s just psuedo-code for understanding.
</div></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="linear-layer"><code>linear</code> layer<a class="anchor-link" href="#linear-layer"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Below code creates a <code>Linear class</code> which represents a <code>Linear</code> layer in our neural-network. The <code>forward function</code> of the class implements the of the <code>layer's forward propagation</code> &amp; the <code>backward function</code> implements the <code>layers's backward propagation</code>. Let's go to detail into what the code means:</p>
<ul>
<li><strong>Forward:</strong><br />
This part is quite straight-forward it computes the dot-product between the <strong><code>input</code></strong> and the <strong><code>weights</code></strong> &amp; adds the <strong><code>bias</code></strong> term to get <strong><code>z</code></strong>. It also stores all the intermidiate values generated to use in the backward pass.</li>
</ul>
<ul>
<li><strong>Backward:</strong><ul>
<li>The backward method of the class <strong><code>Linear</code></strong> takes in the argument <strong><code>grads</code></strong>. </li>
<li><strong><code>grads</code></strong> is the gradient of the loss wrt to the output of the current linear layer ie., <strong><code>dz</code></strong> if we were to follow the nomenclature of our pseudo-code.</li>
<li>To succesfully compute the backward pass for our linear layer we need the following:<ul>
<li><strong><code>grad(z, w)</code></strong> </li>
<li><strong><code>grad(z, b)</code></strong></li>
<li><strong><code>grad(z, a_prev)</code></strong></li>
</ul>
</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong><code>z</code>, <code>w</code>, <code>b</code>, <code>a_prev</code> are the outputs, weights, bias and input-activations of the Linear layer respectively.
</div></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Linear</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">w</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">b</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inp</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Implement the linear part of a layer&#39;s forward propagation.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            inp : activations from previous layer (or input data)</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>

<span class="sd">            z  : the input of the activation function, also called pre-activation parameter </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inp</span> <span class="o">=</span> <span class="n">inp</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">z</span>   <span class="o">=</span> <span class="n">inp</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">z</span>
    
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">grads</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Implement the linear portion of backward propagation for a single layer.</span>

<span class="sd">        Args:</span>
<span class="sd">            grads :  Gradient of the cost with respect to the linear output. </span>
<span class="sd">                     or the accumulated gradients from the prev layers. </span>
<span class="sd">                     This is used for the chain rule to compute the gradients.</span>
<span class="sd">        Returns:</span>
<span class="sd">            da : Gradient of cost wrt to the activation of the previous layer or the input of the </span>
<span class="sd">                 current layer.</span>
<span class="sd">            dw : Gradient of the cost with respect to W</span>
<span class="sd">            db : Gradient of the cost with respect to b</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">m</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># gradient of loss wrt to the weights</span>
        <span class="n">dw</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">m</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inp</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">grads</span><span class="p">)</span>
        <span class="c1"># gradient of the loss wrt to the bias</span>
        <span class="n">db</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">m</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># gradient of the loss wrt to the input of the linear layer</span>
        <span class="c1"># this is used to continue the chain rule</span>
        <span class="n">da_prev</span> <span class="o">=</span> <span class="n">grads</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="o">.</span><span class="n">T</span> 
        <span class="k">return</span> <span class="p">(</span><span class="n">da_prev</span><span class="p">,</span> <span class="n">dw</span><span class="p">,</span> <span class="n">db</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="ReLU-layer"><code>ReLU</code> layer<a class="anchor-link" href="#ReLU-layer"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><strong>Forward</strong>:<br />
The mathematical formula for ReLU is $A = RELU(Z) = max(0, Z)$</li>
<li><strong>Backward</strong>:<br />
During the backward pass the relu accepts the gradients of the <code>loss wrt to the activation</code> i.e, <code>da</code> then computes
the gradients of the <code>loss wrt to the input-of-relu(z)</code> i.e, <code>dz</code>.</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">RelU</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inp</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Implement the RELU function.</span>

<span class="sd">        Args:</span>
<span class="sd">            inp : Output of the linear layer, of any shape</span>

<span class="sd">        Returns:</span>
<span class="sd">            a  : Post-activation parameter, of the same shape as Z</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inp</span> <span class="o">=</span> <span class="n">inp</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inp</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span>
    
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">grads</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Implement the backward propagation for a single RELU unit.</span>

<span class="sd">        Ars:</span>
<span class="sd">            grads : gradients of the loss wrt to the activation output</span>

<span class="sd">        Returns:</span>
<span class="sd">            dz : Gradient of the loss with respect to the input of the activation</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dz</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">dz</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">inp</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="n">dz</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="sigmoid-layer"><code>sigmoid</code> layer<a class="anchor-link" href="#sigmoid-layer"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The sigmoid layer functions in exactly the same way as the <code>ReLU</code> layer . The only difference is the forward pass output calculation.</p>
<p>In the <code>sigmoid layer</code>:  $\sigma(Z) = \frac{1}{ 1 + e^{-(W A + b)}}$</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Sigmoid</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inp</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Implements the sigmoid activation in numpy</span>

<span class="sd">        Args:</span>
<span class="sd">            inp: numpy array of any shape</span>

<span class="sd">        Returns:</span>
<span class="sd">            a  : output of sigmoid(z), same shape as inp</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inp</span> <span class="o">=</span> <span class="n">inp</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span>  <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">inp</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span>
    
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">grads</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Implement the backward propagation for a single sigmoid unit.</span>

<span class="sd">        Args:</span>
<span class="sd">            grads : gradients of the loss wrt to the activation output</span>

<span class="sd">        Returns:</span>
<span class="sd">            dz : Gradient of the loss with respect to the input of the activation</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">s</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">inp</span><span class="p">))</span>
        <span class="n">dz</span> <span class="o">=</span> <span class="n">grads</span> <span class="o">*</span> <span class="n">s</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">s</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">dz</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Loss_function-:">Loss_function :<a class="anchor-link" href="#Loss_function-:"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For this task we are going to use the <a href="https://en.wikipedia.org/wiki/Cross_entropy">CrossEntropy Loss</a></p>
<p>The <code>forward</code> pass of the CrossEntropy Loss is computed as follows: 

$$loss= -\frac{1}{m} \sum\limits_{i = 1}^{m} (y^{(i)}\log\left(yhat^{(i)}\right) + (1-y^{(i)})\log\left(1-yhat^{(i)}\right)) $$
</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">CELoss</span><span class="p">():</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Implement the CrossEntropy loss function.</span>

<span class="sd">        Args:</span>
<span class="sd">            pred   : predicted labels from the neural network</span>
<span class="sd">            target : true &quot;label&quot; labels</span>
<span class="sd">        Returns:</span>
<span class="sd">            loss : cross-entropy loss</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">yhat</span> <span class="o">=</span> <span class="n">pred</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">target</span>
        <span class="n">m</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># commpute loss</span>
        <span class="n">term1</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">yhat</span><span class="p">)))</span>
        <span class="n">term2</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">),(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">yhat</span><span class="p">))))</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="n">m</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">term1</span><span class="o">+</span><span class="n">term2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">loss</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">)</span> <span class="c1"># convert array to a single value number</span>
    
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the gradinets of the loss_fn wrt to the predicted labels</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">         da : derivative of loss_fn wrt to the predicted labels</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># derivative of loss_fn with respect to a [predicted labels]</span>
        <span class="n">da</span> <span class="o">=</span> <span class="o">-</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">yhat</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">yhat</span><span class="p">))</span> 
        <span class="k">return</span> <span class="n">da</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Model:">Model:<a class="anchor-link" href="#Model:"> </a></h2><p><strong>Let's go over the architecture that we are going to use for our neural netwok:</strong></p>
<p>Our model is going to have 2 hidden layers and a output layer. The <code>hidden layers</code> are going to have <code>16 units</code> each followed by a <code>ReLU</code> activation layer and the <code>output layer</code> is going to have <code>1 unit</code> followed by a <code>Sigmoid</code> unit. The ouput layer is going to predict the <code>input</code> is either <code>0</code> or <code>1</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's assemble the layers required to construct out model:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>((10610, 784), (10610, 1))</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nh1</span> <span class="o">=</span> <span class="mi">16</span> <span class="c1"># no. of units in the first hidden layer</span>
<span class="n">nh2</span> <span class="o">=</span> <span class="mi">16</span> <span class="c1"># no. of units in the 2nd hidden layer</span>
<span class="n">nh3</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># no. of units in the output layer</span>

<span class="n">w1</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">nh1</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span>
<span class="n">b1</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">nh1</span><span class="p">))</span>

<span class="n">w2</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">nh1</span><span class="p">,</span> <span class="n">nh2</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span>
<span class="n">b2</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">nh2</span><span class="p">))</span>

<span class="n">w3</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">nh2</span><span class="p">,</span> <span class="n">nh3</span><span class="p">)</span>
<span class="n">b3</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">nh3</span><span class="p">))</span>

<span class="n">w1</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">b1</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">w2</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">b2</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">w3</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">b3</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>((784, 16), (1, 16), (16, 16), (1, 16), (16, 1), (1, 1))</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lin1</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">w1</span><span class="p">,</span><span class="n">b1</span><span class="p">)</span> <span class="c1"># 1 hidden layer</span>
<span class="n">relu1</span> <span class="o">=</span> <span class="n">RelU</span><span class="p">()</span>
<span class="n">lin2</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">w2</span><span class="p">,</span><span class="n">b2</span><span class="p">)</span> <span class="c1"># 2nd hidden layer</span>
<span class="n">relu2</span> <span class="o">=</span> <span class="n">RelU</span><span class="p">()</span>
<span class="n">lin3</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">w3</span><span class="p">,</span><span class="n">b3</span><span class="p">)</span> <span class="c1"># output layer</span>
<span class="n">sigmoid</span> <span class="o">=</span> <span class="n">Sigmoid</span><span class="p">()</span>

<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">CELoss</span><span class="p">()</span> <span class="c1"># loss_fn</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Forward-pass:">Forward pass:<a class="anchor-link" href="#Forward-pass:"> </a></h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">z1</span> <span class="o">=</span> <span class="n">lin1</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
<span class="n">a1</span> <span class="o">=</span> <span class="n">relu1</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">z1</span><span class="p">)</span>
<span class="n">z2</span> <span class="o">=</span> <span class="n">lin2</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">a1</span><span class="p">)</span>
<span class="n">a2</span> <span class="o">=</span> <span class="n">relu2</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">z2</span><span class="p">)</span>
<span class="n">z3</span> <span class="o">=</span> <span class="n">lin3</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">a2</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">z3</span><span class="p">)</span>

<span class="c1"># calculate loss</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loss:&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span> <span class="c1"># print out the loss</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Loss: 0.6954586218304929
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Predictions: &quot;</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Predictions:  [[0.50221048]
 [0.5016568 ]
 [0.50445   ]
 ...
 [0.5006608 ]
 [0.49939964]
 [0.49894181]]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Backward-pass:">Backward pass:<a class="anchor-link" href="#Backward-pass:"> </a></h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">da3</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss_fn</span><span class="o">.</span><span class="n">backward</span><span class="p">())</span>
<span class="n">dz3</span><span class="p">,</span> <span class="n">dw3</span><span class="p">,</span> <span class="n">db3</span> <span class="o">=</span> <span class="n">lin3</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">da3</span><span class="p">)</span>

<span class="n">da2</span> <span class="o">=</span> <span class="n">relu2</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">dz3</span><span class="p">)</span>
<span class="n">dz2</span><span class="p">,</span> <span class="n">dw2</span><span class="p">,</span> <span class="n">db2</span> <span class="o">=</span> <span class="n">lin2</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">da2</span><span class="p">)</span>

<span class="n">da1</span> <span class="o">=</span> <span class="n">relu1</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">dz2</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">dw1</span><span class="p">,</span> <span class="n">db1</span> <span class="o">=</span> <span class="n">lin1</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">da1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Update-parameters:">Update parameters:<a class="anchor-link" href="#Update-parameters:"> </a></h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.0002</span>

<span class="c1"># update parameters </span>
<span class="n">lin1</span><span class="o">.</span><span class="n">w</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dw1</span>
<span class="n">lin2</span><span class="o">.</span><span class="n">w</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dw2</span>
<span class="n">lin3</span><span class="o">.</span><span class="n">w</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dw3</span>

<span class="n">lin1</span><span class="o">.</span><span class="n">b</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">db1</span>
<span class="n">lin2</span><span class="o">.</span><span class="n">b</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">db2</span>
<span class="n">lin3</span><span class="o">.</span><span class="n">b</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">db3</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Putting-it-all-together:">Putting it all together:<a class="anchor-link" href="#Putting-it-all-together:"> </a></h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nh1</span> <span class="o">=</span> <span class="mi">16</span> <span class="c1"># no. of units in the first hidden layer</span>
<span class="n">nh2</span> <span class="o">=</span> <span class="mi">16</span> <span class="c1"># no. of units in the 2nd hidden layer</span>
<span class="n">nh3</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># no. of units in the output layer</span>

<span class="n">w1</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">nh1</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span>
<span class="n">b1</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">nh1</span><span class="p">))</span>

<span class="n">w2</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">nh1</span><span class="p">,</span> <span class="n">nh2</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span>
<span class="n">b2</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">nh2</span><span class="p">))</span>

<span class="n">w3</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">nh2</span><span class="p">,</span> <span class="n">nh3</span><span class="p">)</span>
<span class="n">b3</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">nh3</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="n">w1</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">b1</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">w2</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">b2</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">w3</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">b3</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(784, 16) (1, 16) (16, 16) (1, 16) (16, 1) (1, 1)
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Model</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A simple neural network model</span>
<span class="sd">        The `forward` method computes the forward propagation step of the model</span>
<span class="sd">        The `backward` method computes the backward step propagation of the model</span>
<span class="sd">        The `update_step` method updates the parameters of the model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin1</span>    <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">w1</span><span class="p">,</span><span class="n">b1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu1</span>   <span class="o">=</span> <span class="n">RelU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin2</span>    <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">w2</span><span class="p">,</span><span class="n">b2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu2</span>   <span class="o">=</span> <span class="n">RelU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin3</span>    <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">w3</span><span class="p">,</span><span class="n">b3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">Sigmoid</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">CELoss</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr</span>      <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">losses</span>  <span class="o">=</span> <span class="p">[]</span> <span class="c1"># stores the loss at each iteration</span>


    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">calc_loss</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computs the forward step for out model</span>
<span class="sd">        Returns the loss and the prediction of the model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">out</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu1</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lin1</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">inp</span><span class="p">))</span>
        <span class="n">out</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu2</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lin2</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">out</span><span class="p">))</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lin3</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">out</span><span class="p">))</span>
        
        <span class="k">if</span> <span class="n">calc_loss</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
            <span class="c1"># appending the loss of the current iteration</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">pred</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">pred</span>


    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the backward step</span>
<span class="sd">        and return the gradients of the parameters with the loss</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">da3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="o">.</span><span class="n">backward</span><span class="p">())</span>
        <span class="n">dz3</span><span class="p">,</span> <span class="n">dw3</span><span class="p">,</span> <span class="n">db3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lin3</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">da3</span><span class="p">)</span>

        <span class="n">da2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu2</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">dz3</span><span class="p">)</span>
        <span class="n">dz2</span><span class="p">,</span> <span class="n">dw2</span><span class="p">,</span> <span class="n">db2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lin2</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">da2</span><span class="p">)</span>

        <span class="n">da1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu1</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">dz2</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">dw1</span><span class="p">,</span> <span class="n">db1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lin1</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">da1</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dws</span> <span class="o">=</span> <span class="p">[</span><span class="n">dw1</span><span class="p">,</span> <span class="n">dw2</span><span class="p">,</span> <span class="n">dw3</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">db1</span><span class="p">,</span> <span class="n">db2</span><span class="p">,</span> <span class="n">db3</span><span class="p">]</span>


    <span class="k">def</span> <span class="nf">update_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Performs the update step</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin1</span><span class="o">.</span><span class="n">w</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">dws</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin2</span><span class="o">.</span><span class="n">w</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">dws</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin3</span><span class="o">.</span><span class="n">w</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">dws</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">lin1</span><span class="o">.</span><span class="n">b</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">dbs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin2</span><span class="o">.</span><span class="n">b</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">dbs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin3</span><span class="o">.</span><span class="n">b</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">dbs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nn</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.0005</span><span class="p">)</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">50</span> <span class="c1"># no. of iterations to train</span>

<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">loss</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">update_step</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loss after interation </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2"> is </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Loss after interation 0 is 0.6935
Loss after interation 1 is 0.6829
Loss after interation 2 is 0.6675
Loss after interation 3 is 0.6481
Loss after interation 4 is 0.6228
Loss after interation 5 is 0.5924
Loss after interation 6 is 0.5488
Loss after interation 7 is 0.5149
Loss after interation 8 is 0.4527
Loss after interation 9 is 0.3746
Loss after interation 10 is 0.3095
Loss after interation 11 is 0.2433
Loss after interation 12 is 0.2016
Loss after interation 13 is 0.1698
Loss after interation 14 is 0.1448
Loss after interation 15 is 0.1250
Loss after interation 16 is 0.1091
Loss after interation 17 is 0.0963
Loss after interation 18 is 0.0859
Loss after interation 19 is 0.0773
Loss after interation 20 is 0.0702
Loss after interation 21 is 0.0641
Loss after interation 22 is 0.0590
Loss after interation 23 is 0.0546
Loss after interation 24 is 0.0509
Loss after interation 25 is 0.0476
Loss after interation 26 is 0.0447
Loss after interation 27 is 0.0421
Loss after interation 28 is 0.0399
Loss after interation 29 is 0.0378
Loss after interation 30 is 0.0360
Loss after interation 31 is 0.0344
Loss after interation 32 is 0.0329
Loss after interation 33 is 0.0316
Loss after interation 34 is 0.0304
Loss after interation 35 is 0.0292
Loss after interation 36 is 0.0282
Loss after interation 37 is 0.0273
Loss after interation 38 is 0.0264
Loss after interation 39 is 0.0256
Loss after interation 40 is 0.0248
Loss after interation 41 is 0.0241
Loss after interation 42 is 0.0234
Loss after interation 43 is 0.0228
Loss after interation 44 is 0.0222
Loss after interation 45 is 0.0217
Loss after interation 46 is 0.0212
Loss after interation 47 is 0.0207
Loss after interation 48 is 0.0202
Loss after interation 49 is 0.0198
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p><div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">losses</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;salmon&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Loss per Iteration&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Iteration&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>
</p>
    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Computing-accuracy-of-our-model">Computing accuracy of our model<a class="anchor-link" href="#Computing-accuracy-of-our-model"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Let's check our model performance by computing the <code>accuracy</code> on the <code>validation</code> dataset</strong></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">comp_accuracy</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">targs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fn that computes the accuracy between the predicted values and the targets</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">targs</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
    <span class="c1"># convert probas to 0/1 predictions</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">preds</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">preds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
            <span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy: &quot;</span>  <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">p</span> <span class="o">==</span> <span class="n">targs</span><span class="p">)</span><span class="o">/</span><span class="n">m</span><span class="p">)))</span>    
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">preds</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x_valid</span><span class="p">,</span> <span class="n">calc_loss</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1"># compute accuracy</span>
<span class="n">comp_accuracy</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Accuracy: 0.9965936739659367
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>Nice our model achieves a <code>accuracy</code> of <strong><code>0.9965936739659367</code></strong> on the validation set !
</div></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Getting-predictions-from-our-model">Getting predictions from our model<a class="anchor-link" href="#Getting-predictions-from-our-model"> </a></h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p><div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_inp</span> <span class="o">=</span> <span class="n">x_valid</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Input: &quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">test_inp</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;binary&quot;</span><span class="p">);</span>

<span class="n">loss</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">test_inp</span><span class="p">)</span>
<span class="n">predicted_val</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">pred</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Predicted output: </span><span class="si">{</span><span class="n">predicted_val</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>
</p>
    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Predicted output: 0
</pre>
</div>
</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p><div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_inp</span> <span class="o">=</span> <span class="n">x_valid</span><span class="p">[</span><span class="mi">2000</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Input: &quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">test_inp</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;binary&quot;</span><span class="p">);</span>

<span class="n">loss</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">test_inp</span><span class="p">)</span>
<span class="n">predicted_val</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">pred</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Predicted output: </span><span class="si">{</span><span class="n">predicted_val</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>
</p>
    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Predicted output: 1
</pre>
</div>
</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Summary:">Summary:<a class="anchor-link" href="#Summary:"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>We were able to create a model that can identify classify handwritten digits as either 1's or 0's</li>
<li>We successfully computed the <code>forward</code> and <code>backward</code> progation of a <code>neural network</code> from scratch.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Thanks for reading !</strong></p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="benihime91/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blog/deeplearning%20python3.x%20numpy/2020/09/22/nn-from-scratch.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Tips, Tricks and Tutorials for Deep-Learning enthusiasts.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/benihime91" title="benihime91"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/Ayushma75139217" title="Ayushma75139217"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
